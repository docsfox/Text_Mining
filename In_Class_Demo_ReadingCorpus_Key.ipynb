{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **In-Class Demonstration: Reading in your own Corpus**\n",
        "## *IS 5150*\n",
        "## Name: Key\n",
        "\n",
        "In this brief demonstration we will cover how to read in a new corpus, using a toy corpus of childrens narratives. We will then apply some of the basic text statistics we learned about in the last in-class assignment."
      ],
      "metadata": {
        "id": "0Tu_nAQMHFfa"
      },
      "id": "0Tu_nAQMHFfa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42e6758e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42e6758e",
        "outputId": "72cf5529-7919-4276-9962-ce7ea7753e3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import PlaintextCorpusReader\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # do this step if in colab"
      ],
      "metadata": {
        "id": "mczE9Z18Dv-Z"
      },
      "id": "mczE9Z18Dv-Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eca7fea",
      "metadata": {
        "id": "6eca7fea"
      },
      "outputs": [],
      "source": [
        "corpus_root = '/content/drive/MyDrive/Colab Notebooks/Text Mining/Topic 2/In-Class Assignments/Sample Corpus' # set root directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4491bb29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4491bb29",
        "outputId": "545270bd-feff-457a-8a52-61799f30fb47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Aliens_1.txt',\n",
              " 'LFS_1.txt',\n",
              " 'LFS_2.txt',\n",
              " 'LFS_3.txt',\n",
              " 'McD_1.txt',\n",
              " 'McD_2.txt',\n",
              " 'McD_3.txt',\n",
              " 'McD_4.txt',\n",
              " 'McD_5.txt',\n",
              " 'ON_1.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "wordlists = PlaintextCorpusReader(corpus_root, '.*') # use plaintextcorpusreader on corpus root directory\n",
        "wordlists.fileids() # check fileids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4636ceb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4636ceb",
        "outputId": "e8439f5a-c290-4962-bb17-d99c2cfa8e04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['so', 'one', 'day', 'Lisa', 'and', 'the', 'boy', ...]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "wordlists.words('McD_1.txt') # examine words on one fileid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c121c903",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c121c903",
        "outputId": "9c53fc80-488a-4b76-a54f-684eb97a3f4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "258"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(wordlists.words('McD_1.txt')) # check total number of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70918cd5",
      "metadata": {
        "id": "70918cd5"
      },
      "outputs": [],
      "source": [
        "story1 = wordlists.words('McD_1.txt') # examine unique words in first story\n",
        "set(story1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4b8396f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4b8396f",
        "outputId": "c4b9cb7e-5675-487d-9d2e-88e8052ade67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg word len =  4 Avg sent len =  12 Lex_Div =  2.06 Text: Aliens_1.txt\n",
            "Avg word len =  4 Avg sent len =  9 Lex_Div =  1.81 Text: LFS_1.txt\n",
            "Avg word len =  4 Avg sent len =  9 Lex_Div =  1.58 Text: LFS_2.txt\n",
            "Avg word len =  4 Avg sent len =  9 Lex_Div =  2.24 Text: LFS_3.txt\n",
            "Avg word len =  4 Avg sent len =  11 Lex_Div =  2.53 Text: McD_1.txt\n",
            "Avg word len =  4 Avg sent len =  11 Lex_Div =  2.24 Text: McD_2.txt\n",
            "Avg word len =  4 Avg sent len =  11 Lex_Div =  2.01 Text: McD_3.txt\n",
            "Avg word len =  5 Avg sent len =  13 Lex_Div =  1.95 Text: McD_4.txt\n",
            "Avg word len =  4 Avg sent len =  8 Lex_Div =  1.7 Text: McD_5.txt\n",
            "Avg word len =  4 Avg sent len =  9 Lex_Div =  1.64 Text: ON_1.txt\n"
          ]
        }
      ],
      "source": [
        "for fileid in wordlists.fileids():\n",
        "  num_chars = len(wordlists.raw(fileid))\n",
        "  num_words = len(wordlists.words(fileid))\n",
        "  num_sents = len(wordlists.sents(fileid))\n",
        "  num_vocab = len(set(word.lower() for word in wordlists.words(fileid))) #set all words to lowercase to avoid double-counting\n",
        "  print(\"Avg word len = \", round(num_chars/num_words),\n",
        "        \"Avg sent len = \", round(num_words/num_sents), \n",
        "        \"Lex_Div = \", round(num_words/num_vocab,2), \n",
        "        \"Text:\", fileid)   # run some basic text statistics on all texts"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}