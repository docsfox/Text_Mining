{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **In-Class Assignment: Annotation, POS Tagging & Syntax Parsing**\n",
        "## *IS 5150*\n",
        "## Name: Key"
      ],
      "metadata": {
        "id": "ZH5HIUo6Crqv"
      },
      "id": "ZH5HIUo6Crqv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "I wanted to cover this during the NLP pipeline, but we ran out of time. This topic is related to annotation is in a sense, another form of feature engineering or metadata creation, in that we're extracting information from raw text to induce more meaning from the text -- but it's not feature engineering in that we're not quantifying the text.\n",
        "\n",
        "Instead, we're applying some useful labels to the text that speak to its structure. This can be helpful in a number of different text mining tasks, including semantic analysis and named entity recognition (among others). \n",
        "\n",
        "In this in-class assignment, we'll use some pretrained annotation models to apply part-of-speech tags to text, as well as to apply different types of syntactic parsing schemes to the text. We will also develop our own deterministic POS tagging model and compare it against pretrained ones.\n",
        "\n",
        "To begin, let's import `nltk`, `spacy`, `graphviz`, `pydot_ng`, `pandas`, and `os`. You may also need to install some software called *GhostScript*, but we'll see..."
      ],
      "metadata": {
        "id": "EtcRJDf3C7Ml"
      },
      "id": "EtcRJDf3C7Ml"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8999ed12",
      "metadata": {
        "id": "8999ed12"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "#nltk.download('all', halt_on_error = False)\n",
        "\n",
        "import spacy\n",
        "spacy.load('en_core_web_sm')\n",
        "\n",
        "import graphviz\n",
        "import pydot_ng\n",
        "!pip install svgling\n",
        "import svgling\n",
        "\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad0ed4fb",
      "metadata": {
        "id": "ad0ed4fb"
      },
      "source": [
        "[Install GhostScript Windows](https://ghostscript.en.uptodown.com/windows/download)\n",
        "\n",
        "\n",
        "[Install GhostScript Mac OSX](https://macappstore.org/ghostscript/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f1d5abd",
      "metadata": {
        "id": "9f1d5abd"
      },
      "outputs": [],
      "source": [
        "# for windows users: set the path to your ghostcript bin folder from program files\n",
        "os.environ['PATH'] = os.environ['Path']+\";C:\\Program Files\\gs\\gs9.56.1\" # run if using jupyter notebooks/lab"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec76d248",
      "metadata": {
        "id": "ec76d248"
      },
      "source": [
        "## **POS Tagging with Spacy**\n",
        "\n",
        "First, let's try out a pretrained POS tagging model from Spacy (the en_core_web_sm model). We will apply it to an example news sentence, since this model was trained on a corpus of WSJ articles (as is the next one)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c535d44",
      "metadata": {
        "id": "2c535d44"
      },
      "outputs": [],
      "source": [
        "sentence = \"US unveils world's most powerful supercomputer, beats China.\"\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f8098b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "8f8098b2",
        "outputId": "ac9340de-d8db-4787-9199-db9d0ffe7cc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0        1      2     3     4         5              6      7   \\\n",
              "Word         US  unveils  world    's  most  powerful  supercomputer      ,   \n",
              "POS Tag     NNP      VBZ     NN   POS   RBS        JJ             NN      ,   \n",
              "Tag type  PROPN     VERB   NOUN  PART   ADV       ADJ           NOUN  PUNCT   \n",
              "\n",
              "             8      9      10  \n",
              "Word      beats  China      .  \n",
              "POS Tag     VBZ    NNP      .  \n",
              "Tag type   VERB  PROPN  PUNCT  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6aa1d11-ec03-4628-96c0-027a7485899f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Word</th>\n",
              "      <td>US</td>\n",
              "      <td>unveils</td>\n",
              "      <td>world</td>\n",
              "      <td>'s</td>\n",
              "      <td>most</td>\n",
              "      <td>powerful</td>\n",
              "      <td>supercomputer</td>\n",
              "      <td>,</td>\n",
              "      <td>beats</td>\n",
              "      <td>China</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>POS Tag</th>\n",
              "      <td>NNP</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>NN</td>\n",
              "      <td>POS</td>\n",
              "      <td>RBS</td>\n",
              "      <td>JJ</td>\n",
              "      <td>NN</td>\n",
              "      <td>,</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>NNP</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tag type</th>\n",
              "      <td>PROPN</td>\n",
              "      <td>VERB</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>PART</td>\n",
              "      <td>ADV</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>VERB</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PUNCT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6aa1d11-ec03-4628-96c0-027a7485899f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6aa1d11-ec03-4628-96c0-027a7485899f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6aa1d11-ec03-4628-96c0-027a7485899f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "sentence_nlp = nlp(sentence) #tokenize sentence\n",
        "\n",
        "spacy_pos_tagged = [(word, word.tag_, word.pos_) for word in sentence_nlp]\n",
        "pd.DataFrame(spacy_pos_tagged, columns = ['Word', 'POS Tag', 'Tag type']).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e01cdb2",
      "metadata": {
        "id": "6e01cdb2",
        "outputId": "87697773-f995-4257-9c5d-7884c1124b42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'particle'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spacy.explain(\"PART\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "101e2613",
      "metadata": {
        "id": "101e2613"
      },
      "source": [
        "## **POS Tagging with NLTK**\n",
        "\n",
        "Now let's try out the POS tagging model from `nltk` and examine whether there are any differences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5059ceb9",
      "metadata": {
        "id": "5059ceb9",
        "outputId": "3fea6a32-4ff7-4456-e181-de1fcbd9ed3e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Word</th>\n",
              "      <td>US</td>\n",
              "      <td>unveils</td>\n",
              "      <td>world</td>\n",
              "      <td>'s</td>\n",
              "      <td>most</td>\n",
              "      <td>powerful</td>\n",
              "      <td>supercomputer</td>\n",
              "      <td>,</td>\n",
              "      <td>beats</td>\n",
              "      <td>China</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pos Tag</th>\n",
              "      <td>NNP</td>\n",
              "      <td>JJ</td>\n",
              "      <td>NN</td>\n",
              "      <td>POS</td>\n",
              "      <td>RBS</td>\n",
              "      <td>JJ</td>\n",
              "      <td>NN</td>\n",
              "      <td>,</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>NNP</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0        1      2    3     4         5              6  7      8   \\\n",
              "Word      US  unveils  world   's  most  powerful  supercomputer  ,  beats   \n",
              "Pos Tag  NNP       JJ     NN  POS   RBS        JJ             NN  ,    VBZ   \n",
              "\n",
              "            9  10  \n",
              "Word     China  .  \n",
              "Pos Tag    NNP  .  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk_pos_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
        "pd.DataFrame(nltk_pos_tagged, columns = ['Word', 'Pos Tag']).T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6f8c728",
      "metadata": {
        "id": "d6f8c728"
      },
      "source": [
        "**Are there any differences between the Spacy and NLTK pos taggers? Why could this occur?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c6db51a",
      "metadata": {
        "id": "4c6db51a"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6f18483b",
      "metadata": {
        "id": "6f18483b"
      },
      "source": [
        "## **Building our own POS tagger**\n",
        "\n",
        "To understand why there are different POS tags applied to the same sentence based on different models, it would be helpful to see how POS taggers can be constructed. We'll try out a few different methods, including both deterministic (i.e., rule-based) and learning based approaches:\n",
        "\n",
        "Let's establish a baseline `accuracy` for our taggers; which would be just be applying a 'default tag' (most common class) to all words. We want to achieve higher accuracy in the taggers we produce.\n",
        "\n",
        "Our first step is to bring in the `treebank` POS tagged setences from `nltk`, we will use a portion of these sentences as 'training data' to construct our taggers, and the remaning sentences as a 'test set' to evaluate its accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25b36d05",
      "metadata": {
        "id": "25b36d05"
      },
      "outputs": [],
      "source": [
        "nltk.download('treebank')\n",
        "from nltk.corpus import treebank\n",
        "\n",
        "data = treebank.tagged_sents()\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95b46b31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95b46b31",
        "outputId": "af690867-6698-459d-ae90-5ac43b6bb24c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "train_data = data[:3500]\n",
        "test_data = data[3500:]\n",
        "print(train_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f459a3a0",
      "metadata": {
        "id": "f459a3a0"
      },
      "source": [
        "#### **Default tagging - baseline majority class tagger**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4369688c",
      "metadata": {
        "id": "4369688c",
        "outputId": "77f9a6fc-34ee-4beb-ee0d-9d5bc62e44c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1454158195372253"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tag import DefaultTagger\n",
        "dt = DefaultTagger('NN') #will tag all words in the test set as nouns\n",
        "\n",
        "dt.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afc3d7d3",
      "metadata": {
        "id": "afc3d7d3",
        "outputId": "e789fcfb-490e-45ed-c630-327b7b17e76e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('US', 'NN'),\n",
              " ('unveils', 'NN'),\n",
              " ('world', 'NN'),\n",
              " (\"'s\", 'NN'),\n",
              " ('most', 'NN'),\n",
              " ('powerful', 'NN'),\n",
              " ('supercomputer', 'NN'),\n",
              " (',', 'NN'),\n",
              " ('beats', 'NN'),\n",
              " ('China', 'NN'),\n",
              " ('.', 'NN')]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dt.tag(nltk.word_tokenize(sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What can we ascertain from this default tagging method?**"
      ],
      "metadata": {
        "id": "drYk7f8mIEev"
      },
      "id": "drYk7f8mIEev"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uw7kMn79IJAN"
      },
      "id": "uw7kMn79IJAN"
    },
    {
      "cell_type": "markdown",
      "id": "2efdc7ab",
      "metadata": {
        "id": "2efdc7ab"
      },
      "source": [
        "#### **Deterministic POS Taggin with Regex**\n",
        "\n",
        "See, I told you regex would keep coming up. In our first attempt of creating a better than baseline POS tagger, let's use some regex patterns to write a rule-set for POS tagging:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c69b1dde",
      "metadata": {
        "id": "c69b1dde"
      },
      "source": [
        "**What are some common suffixes we could use to try and identify POS?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "454458d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "454458d9",
        "outputId": "6f2b125a-7c97-45ea-957d-1b2237fd2e72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24039113176493368"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from nltk.tag import RegexpTagger\n",
        "\n",
        "patterns = [\n",
        "    (r'.*ing$', 'VBG'),              # gerunds\n",
        "    (r'.*ed$', 'VBD'),               # simple past tense\n",
        "    (r'.*es$', 'VBZ'),               # 3rd singular present\n",
        "    (r'.*ould$', 'MD'),              # modals\n",
        "    (r'.*\\'s$', 'NN$'),              # possessive nouns\n",
        "    (r'.*s$', 'NNS'),                # plural nouns\n",
        "    (r'^-?[0-9]+(.[0-9]+)?$', 'CD'), # cardinal numbers\n",
        "    (r'.*', 'NN')                    # nouns (default)\n",
        "]\n",
        "\n",
        "rt = RegexpTagger(patterns)\n",
        "\n",
        "rt.accuracy(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e79da75",
      "metadata": {
        "id": "9e79da75",
        "outputId": "f96cdef0-4736-428a-9575-a483525be0e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('US', 'NN'),\n",
              " ('unveils', 'NNS'),\n",
              " ('world', 'NN'),\n",
              " (\"'s\", 'NN$'),\n",
              " ('most', 'NN'),\n",
              " ('powerful', 'NN'),\n",
              " ('supercomputer', 'NN'),\n",
              " (',', 'NN'),\n",
              " ('beats', 'NNS'),\n",
              " ('China', 'NN'),\n",
              " ('.', 'NN')]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rt.tag(nltk.word_tokenize(sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f26aec72",
      "metadata": {
        "id": "f26aec72"
      },
      "source": [
        "**What are some issues our regex pattern based tokenizer encountered?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bba3af0f",
      "metadata": {
        "id": "bba3af0f"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d3044295",
      "metadata": {
        "id": "d3044295"
      },
      "source": [
        "### **Learning Based Approaches**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcc16f14",
      "metadata": {
        "id": "fcc16f14"
      },
      "source": [
        "#### **N gram Taggers**\n",
        "\n",
        "This first learning approach identies common unigrams (one word) and bigrams (two word pairs) and tries to learn their POS tags from the labeled training data. Then it tries to predict the POS tag based on the unigram and bigrams in the test set.\n",
        "\n",
        "Let's try it out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79e7fb3e",
      "metadata": {
        "id": "79e7fb3e"
      },
      "outputs": [],
      "source": [
        "from nltk.tag import UnigramTagger\n",
        "from nltk.tag import BigramTagger\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "ut = UnigramTagger(train_data) # train the unigram tagger on the training data\n",
        "bt = BigramTagger(train_data)  # train the unigram tagger on the training data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ut.accuracy(test_data))\n",
        "print(ut.tag(nltk.word_tokenize(sentence)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6sevSRbJMHH",
        "outputId": "f0413eef-0cd3-419c-d248-6c6473e73cf6"
      },
      "id": "f6sevSRbJMHH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8607803272340013\n",
            "[('US', 'NNP'), ('unveils', None), ('world', 'NN'), (\"'s\", 'POS'), ('most', 'JJS'), ('powerful', 'JJ'), ('supercomputer', 'NN'), (',', ','), ('beats', None), ('China', 'NNP'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86d8b733",
      "metadata": {
        "id": "86d8b733"
      },
      "source": [
        "**This learning based method certainly outperforms the previous deterministic approaches, but still tags some words incorrectly as 'None'. Why might this happen in a learning based method when it didn't occur when using the less accurate deterministic methods?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3bf4971",
      "metadata": {
        "id": "a3bf4971"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17a31f60",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17a31f60",
        "outputId": "1b7bafda-b3c4-4609-f6e0-71de25d6c7ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.13466937748087907\n",
            "[('US', None), ('unveils', None), ('world', None), (\"'s\", None), ('most', None), ('powerful', None), ('supercomputer', None), (',', None), ('beats', None), ('China', None), ('.', None)]\n"
          ]
        }
      ],
      "source": [
        "print(bt.accuracy(test_data))\n",
        "print(bt.tag(nltk.word_tokenize(sentence)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fd185d5",
      "metadata": {
        "id": "9fd185d5"
      },
      "source": [
        "**Based on what we just discussed, why might the bigram tagger have performed significantly worse than the unigram tagger?**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZVT56wbOJjbG"
      },
      "id": "ZVT56wbOJjbG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We can get the best of both worlds using a combined tagging model, it will first search for matching bigrams, then matching unigrams, then apply our regex rules if there are no learned matches:**"
      ],
      "metadata": {
        "id": "Vc4HPhlpJmT_"
      },
      "id": "Vc4HPhlpJmT_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8838de60",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8838de60",
        "outputId": "2fb6640b-13ac-4d72-8dfb-44adf2e7e12e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9103495014038145\n",
            "[('US', 'NNP'), ('unveils', 'NNS'), ('world', 'NN'), (\"'s\", 'POS'), ('most', 'RBS'), ('powerful', 'JJ'), ('supercomputer', 'NN'), (',', ','), ('beats', 'NNS'), ('China', 'NNP'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "def combined_tagger(train_data, taggers, backoff=None):\n",
        "    for tagger in taggers:\n",
        "        backoff = tagger(train_data, backoff=backoff)\n",
        "    return backoff\n",
        "\n",
        "ct = combined_tagger(train_data = train_data, taggers = [UnigramTagger, BigramTagger],\n",
        "                     backoff=rt) #uses regex as the backup\n",
        "\n",
        "print(ct.accuracy(test_data))\n",
        "print(ct.tag(nltk.word_tokenize(sentence)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da72c552",
      "metadata": {
        "id": "da72c552"
      },
      "source": [
        "**Why might the POS tagger mark 'unveils' as NNS - plural noun?**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "s3UJ_JBOKDl3"
      },
      "id": "s3UJ_JBOKDl3"
    },
    {
      "cell_type": "markdown",
      "id": "2421c62c",
      "metadata": {
        "id": "2421c62c"
      },
      "source": [
        "### **Naive Bayes Classifier**\n",
        "Beyond just training a tagger on the tags of individual words or bi-grams, the `nltk NaiveBayesClassifier` trains the algorithm on additional features like word, previous word, tag, previous tag, case, etc.\n",
        "\n",
        "It's okay if you're not familiar with Naive Bayes, we will cover classification methods in more detail during Unit 2. For now, know that it is a method of supervised learning designed to learn and then predict class labels, like POS tags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "504adfbe",
      "metadata": {
        "id": "504adfbe",
        "outputId": "3afd4ac5-7c7c-4f09-88c8-e731355b0dc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9306806079969019\n",
            "[('US', 'PRP'), ('unveils', 'VBZ'), ('world', 'VBN'), (\"'s\", 'POS'), ('most', 'JJS'), ('powerful', 'JJ'), ('supercomputer', 'NN'), (',', ','), ('beats', 'VBZ'), ('China', 'NNP'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "from nltk.classify import NaiveBayesClassifier, MaxentClassifier\n",
        "from nltk.tag.sequential import ClassifierBasedPOSTagger\n",
        "\n",
        "nbt = ClassifierBasedPOSTagger(train = train_data,\n",
        "                              classifier_builder=NaiveBayesClassifier.train) # train using supervised learning algorithm\n",
        "\n",
        "\n",
        "print(nbt.evaluate(test_data))\n",
        "print(nbt.tag(nltk.word_tokenize(sentence)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa1a3cbc",
      "metadata": {
        "id": "aa1a3cbc",
        "outputId": "3dd89e5e-3c33-4367-d6e2-7838595668f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9090909090909091"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "10/11 # what's the accuracy on our sample sentence?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ed2643d",
      "metadata": {
        "id": "4ed2643d"
      },
      "source": [
        "**Here we see a slight drop in performance on our example sentence, but overall still high accuracy. How might we expect this same POS tagger to perform on literature? Tweets?**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QFTWeRs9KksK"
      },
      "id": "QFTWeRs9KksK"
    },
    {
      "cell_type": "markdown",
      "id": "f38bfc60",
      "metadata": {
        "id": "f38bfc60"
      },
      "source": [
        "# **Syntax Parsing**\n",
        "\n",
        "We won't train our own syntax parsers because they're more complicated than POS taggers; dealing with classifying different levels of sentence structures, instead of just classifying word classes. \n",
        "\n",
        "However, we will take a look at some pretrained parsers for performing Dependency and Constituency parsing."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec114b48",
      "metadata": {
        "id": "ec114b48"
      },
      "source": [
        "#### **Dependency Parsing with Spacy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f40f97ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f40f97ff",
        "outputId": "ce71a0e8-6964-48d4-f2d1-127f69bcdbd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]<---The[det]--->[]\n",
            "---------\n",
            "['The']<---fox[nsubj]--->[]\n",
            "---------\n",
            "['fox']<---jumped[ROOT]--->['over', 'and', 'went']\n",
            "---------\n",
            "[]<---over[prep]--->['fence']\n",
            "---------\n",
            "[]<---the[det]--->[]\n",
            "---------\n",
            "['the']<---fence[pobj]--->[]\n",
            "---------\n",
            "[]<---and[cc]--->[]\n",
            "---------\n",
            "[]<---the[det]--->[]\n",
            "---------\n",
            "['the']<---cow[nsubj]--->[]\n",
            "---------\n",
            "['cow']<---went[conj]--->['moo', '.']\n",
            "---------\n",
            "[]<---moo[acomp]--->[]\n",
            "---------\n",
            "[]<---.[punct]--->[]\n",
            "---------\n"
          ]
        }
      ],
      "source": [
        "sentence = \"The fox jumped over the fence and the cow went moo.\"\n",
        "sentence_nlp = nlp(sentence)\n",
        "\n",
        "dependency_pattern = '{left}<---{word}[{w_type}]--->{right}\\n---------'\n",
        "for token in sentence_nlp:\n",
        "    print(dependency_pattern.format(word=token.orth_,\n",
        "                                   w_type=token.dep_,\n",
        "                                   left=[t.orth_\n",
        "                                        for t \n",
        "                                        in token.lefts],\n",
        "                                   right=[t.orth_\n",
        "                                         for t in\n",
        "                                         token.rights]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ace1ba5f",
      "metadata": {
        "id": "ace1ba5f",
        "outputId": "a8a2f65d-0dda-4811-ed05-3524524b5720"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"66b69c17ed124fdaa2cd523e01db636b-0\" class=\"displacy\" width=\"1260\" height=\"357.0\" direction=\"ltr\" style=\"max-width: none; height: 357.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">fox</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">jumped</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">over</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">fence</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">and</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">CCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">cow</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">went</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">moo.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-66b69c17ed124fdaa2cd523e01db636b-0-0\" stroke-width=\"2px\" d=\"M70,222.0 C70,167.0 145.0,167.0 145.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-66b69c17ed124fdaa2cd523e01db636b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,224.0 L64,214.0 76,214.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-66b69c17ed124fdaa2cd523e01db636b-0-1\" stroke-width=\"2px\" d=\"M180,222.0 C180,167.0 255.0,167.0 255.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-66b69c17ed124fdaa2cd523e01db636b-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M180,224.0 L174,214.0 186,214.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-66b69c17ed124fdaa2cd523e01db636b-0-2\" stroke-width=\"2px\" d=\"M290,222.0 C290,167.0 365.0,167.0 365.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-66b69c17ed124fdaa2cd523e01db636b-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M365.0,224.0 L371.0,214.0 359.0,214.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-66b69c17ed124fdaa2cd523e01db636b-0-3\" stroke-width=\"2px\" d=\"M510,222.0 C510,167.0 585.0,167.0 585.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-66b69c17ed124fdaa2cd523e01db636b-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M510,224.0 L504,214.0 516,214.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-66b69c17ed124fdaa2cd523e01db636b-0-4\" stroke-width=\"2px\" d=\"M400,222.0 C400,112.0 590.0,112.0 590.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-66b69c17ed124fdaa2cd523e01db636b-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M590.0,224.0 L596.0,214.0 584.0,214.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-66b69c17ed124fdaa2cd523e01db636b-0-5\" stroke-width=\"2px\" d=\"M290,222.0 C290,57.0 705.0,57.0 705.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-66b69c17ed124fdaa2cd523e01db636b-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M705.0,224.0 L711.0,214.0 699.0,214.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-66b69c17ed124fdaa2cd523e01db636b-0-6\" stroke-width=\"2px\" d=\"M840,222.0 C840,167.0 915.0,167.0 915.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-66b69c17ed124fdaa2cd523e01db636b-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M840,224.0 L834,214.0 846,214.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-66b69c17ed124fdaa2cd523e01db636b-0-7\" stroke-width=\"2px\" d=\"M950,222.0 C950,167.0 1025.0,167.0 1025.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-66b69c17ed124fdaa2cd523e01db636b-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M950,224.0 L944,214.0 956,214.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-66b69c17ed124fdaa2cd523e01db636b-0-8\" stroke-width=\"2px\" d=\"M290,222.0 C290,2.0 1040.0,2.0 1040.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-66b69c17ed124fdaa2cd523e01db636b-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1040.0,224.0 L1046.0,214.0 1034.0,214.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-66b69c17ed124fdaa2cd523e01db636b-0-9\" stroke-width=\"2px\" d=\"M1060,222.0 C1060,167.0 1135.0,167.0 1135.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-66b69c17ed124fdaa2cd523e01db636b-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1135.0,224.0 L1141.0,214.0 1129.0,214.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from spacy import displacy\n",
        "\n",
        "displacy.render(sentence_nlp, jupyter = True,\n",
        "               options={'distance': 110,\n",
        "                       'arrow_stroke': 2,\n",
        "                       'arrow_width': 8})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is the root of the sentence? How do you know? Why should we care about the root and its dependencies?**"
      ],
      "metadata": {
        "id": "35gwxSSGLF_F"
      },
      "id": "35gwxSSGLF_F"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n0KyN7OBLOMp"
      },
      "id": "n0KyN7OBLOMp"
    },
    {
      "cell_type": "markdown",
      "id": "a6e8e9ea",
      "metadata": {
        "id": "a6e8e9ea"
      },
      "source": [
        "#### **Constituency Parsing with nltk**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's try out constuency parsing, which is a bit more involved to implement.\n",
        "\n",
        "**How is constituency parsing different from dependency parsing?**"
      ],
      "metadata": {
        "id": "oBSMSIRALk09"
      },
      "id": "oBSMSIRALk09"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ni141RIQLwQ_"
      },
      "id": "Ni141RIQLwQ_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c5c789e",
      "metadata": {
        "id": "1c5c789e"
      },
      "outputs": [],
      "source": [
        "from nltk import Nonterminal\n",
        "from nltk.corpus import treebank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2feb5181",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2feb5181",
        "outputId": "23c53f26-4b1e-42a9-f368-177839ab3842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP-SBJ (NNP Mr.) (NNP Vinken))\n",
            "  (VP\n",
            "    (VBZ is)\n",
            "    (NP-PRD\n",
            "      (NP (NN chairman))\n",
            "      (PP\n",
            "        (IN of)\n",
            "        (NP\n",
            "          (NP (NNP Elsevier) (NNP N.V.))\n",
            "          (, ,)\n",
            "          (NP (DT the) (NNP Dutch) (VBG publishing) (NN group))))))\n",
            "  (. .))\n"
          ]
        }
      ],
      "source": [
        "training_set = treebank.parsed_sents()\n",
        "print(training_set[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a2e2ab2",
      "metadata": {
        "id": "7a2e2ab2"
      },
      "source": [
        "**What does this mean in English? Let's break it down...**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a simple clause where the highest order phrase is the subject noun phrase; *Mr. Vinken* is our subject; this is followed by a verb phrase which is attached to our subject, and specifies its relation to the next noun phrase, which tells us what Mr. Vinken is -- *a chairman* -- followed by a prepositional phrase to indicate what he is the chairman of -- *Elsevier N.V., the Dutch publishing group*."
      ],
      "metadata": {
        "id": "p-FBR6vCL5nn"
      },
      "id": "p-FBR6vCL5nn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0f5ccb7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0f5ccb7",
        "outputId": "708f4873-e1ba-4e29-9e95-66131f8b0423"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[NN -> 'book',\n",
              " JJ -> '54-year-old',\n",
              " NNP -> 'Woolworth',\n",
              " VP -> ADVP-MNR VBN NP PP-CLR,\n",
              " VB -> 'recruit',\n",
              " NP-SBJ-47 -> PRP$ JJ NN,\n",
              " VB -> 'tuck',\n",
              " NNP -> 'Army',\n",
              " CD -> '325,000',\n",
              " NNS -> 'suitors']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# extract production rules (grammar rules) for all annotated sentences from nltk treebank \n",
        "\n",
        "treebank_productions = list(\n",
        "                        set(production\n",
        "                           for sent in training_set\n",
        "                           for production in sent.productions()\n",
        "                           )\n",
        "                        )\n",
        "\n",
        "treebank_productions[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed127e10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed127e10",
        "outputId": "30457053-f5a4-4450-a223-889ed9a60265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT'), ('fox', 'NN'), ('jumped', 'VBD'), ('over', 'IN'), ('the', 'DT'), ('fence', 'NN'), ('and', 'CC'), ('the', 'DT'), ('cow', 'NN'), ('went', 'VBD'), ('moo', 'NN'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "tokens = nltk.word_tokenize(sentence)\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "tagged_sent = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
        "print(tagged_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e150928c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "e150928c",
        "outputId": "65a46855-7ea1-4018-9a62-83543d1535a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ProbabilisticTree('S', [ProbabilisticTree('NP-SBJ-97', [ProbabilisticTree('DT', ['The']) (p=0.06666666666666667), ProbabilisticTree('NN', ['fox']) (p=0.0007530120481927711)]) (p=5.020080321285141e-05), ProbabilisticTree('VP', [ProbabilisticTree('VBD', ['jumped']) (p=0.005758157389635317), ProbabilisticTree('SBAR-TMP', [ProbabilisticTree('WHPP-1', [ProbabilisticTree('IN', ['over']) (p=0.024793388429752067), ProbabilisticTree('WHNP', [ProbabilisticTree('DT', ['the']) (p=0.1111111111111111), ProbabilisticTree('NN', ['fence']) (p=0.0007530120481927711)]) (p=7.606182304977486e-06)]) (p=1.885830323548137e-07), ProbabilisticTree('S', [ProbabilisticTree('CC', ['and']) (p=0.15), ProbabilisticTree('NP-SBJ-51', [ProbabilisticTree('DT', ['the']) (p=0.1111111111111111), ProbabilisticTree('NN', ['cow']) (p=0.0011295180722891566)]) (p=6.275100401606425e-05), ProbabilisticTree('VP', [ProbabilisticTree('VBD', ['went']) (p=0.005758157389635317), ProbabilisticTree('NP-CLR', [ProbabilisticTree('NN', ['moo']) (p=0.0007530120481927711)]) (p=0.00015060240963855423)]) (p=4.080905308033535e-10), ProbabilisticTree('.', ['.']) (p=0.6)]) (p=2.985399155909731e-18)]) (p=3.127753475616435e-26)]) (p=8.475339665213328e-32)]) (p=5.511254646314096e-39)"
            ],
            "image/svg+xml": "<svg baseProfile=\"full\" height=\"360px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,560.0,360.0\" width=\"560px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"15.7143%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP-SBJ-97</text></svg><svg width=\"50%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">The</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"50%\" x=\"50%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">fox</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.85714%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"84.2857%\" x=\"15.7143%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"13.5593%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBD</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">jumped</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"6.77966%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"86.4407%\" x=\"13.5593%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">SBAR-TMP</text></svg><svg width=\"35.2941%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">WHPP-1</text></svg><svg width=\"33.3333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">over</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16.6667%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"66.6667%\" x=\"33.3333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">WHNP</text></svg><svg width=\"41.6667%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20.8333%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"58.3333%\" x=\"41.6667%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">fence</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70.8333%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"66.6667%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"17.6471%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"64.7059%\" x=\"35.2941%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"15.1515%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CC</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">and</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.57576%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"33.3333%\" x=\"15.1515%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP-SBJ-51</text></svg><svg width=\"50%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"50%\" x=\"50%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cow</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"31.8182%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"42.4242%\" x=\"48.4848%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"42.8571%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBD</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">went</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"21.4286%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"57.1429%\" x=\"42.8571%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP-CLR</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">moo</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"71.4286%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"69.697%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"9.09091%\" x=\"90.9091%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"95.4545%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"67.6471%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"56.7797%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"57.8571%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "for word, tag in tagged_sent:\n",
        "    t = nltk.Tree.fromstring(\"(\"+ tag +\" \"+ word +\")\")\n",
        "    for production in t.productions():\n",
        "        treebank_productions.append(production)\n",
        "        \n",
        "        \n",
        "treebank_grammar = nltk.grammar.induce_pcfg(Nonterminal('S'), treebank_productions)\n",
        "\n",
        "viterbi_parser = nltk.ViterbiParser(treebank_grammar)\n",
        "result = list(viterbi_parser.parse(tokens))[0]\n",
        "\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e62f0128",
      "metadata": {
        "id": "e62f0128"
      },
      "source": [
        "[Penn Treebank Constituency Tags](http://surdeanu.cs.arizona.edu/mihai/teaching/ista555-fall13/readings/PennTreebankConstituents.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34677777",
      "metadata": {
        "id": "34677777"
      },
      "source": [
        "**How does the Constituency Parse tree differ from the Depedency parse graph in its representation of the sentence \"The fox jumped over the fence and the cow went moo.\"?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "394a9774",
      "metadata": {
        "id": "394a9774"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
