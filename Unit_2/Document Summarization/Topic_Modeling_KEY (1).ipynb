{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNxfC0djAxiX91KP/KvyBHe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **In-Class Assignment: Topic Modeling**\n","\n","## *IS 5150*\n","## Name: KEY\n","\n","In the previous in-class assignment we went through different methods in key-phrase extraction. Both are relatively simple and easy to implement, but don't always yield the most useful information in regards to determining a document's overall theme/topic. Topic modeling is a more sophisticated approach to extracting topics/themes from a corpus, and there are several unsupervised approaches we can take to accomplishing this text mining task:\n","\n","\n","\n","*   Latent Semantic Indexing\n","*   Latent Dirichlet Allocation\n","\n","In this in-class assignment we will implement the above methods on a corpus of research papers from the NeurIPS conference to try and extract meaningful topic labels for these papers. We will begin with our oldest and most basic method, LSI and then end of NMF. Remember it's worth learning both newer and more traditional methods, because you never know which will perform best on any given task or dataset!\n"],"metadata":{"id":"dYOHte7NlGJR"}},{"cell_type":"code","source":["# load all dependencies\n","\n","import nltk\n","#nltk.download()  #stopwords, wordnet, omw-1.4\n","import gensim\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"],"metadata":{"id":"giM7h9Q9r4wN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **1) Data Retrieval**\n","\n","We will be downloading the dataset directly using the following commands:"],"metadata":{"id":"vS2-VuCrr4gS"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E_TCas0xk2qc","executionInfo":{"status":"ok","timestamp":1662835231862,"user_tz":360,"elapsed":1411,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"6acbe33f-4faf-4ebb-e88c-cf483eef82eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-09-10 18:40:30--  https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz\n","Resolving cs.nyu.edu (cs.nyu.edu)... 216.165.22.203\n","Connecting to cs.nyu.edu (cs.nyu.edu)|216.165.22.203|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 12851423 (12M) [application/x-gzip]\n","Saving to: ‘nips12raw_str602.tgz’\n","\n","nips12raw_str602.tg 100%[===================>]  12.26M  16.4MB/s    in 0.7s    \n","\n","2022-09-10 18:40:31 (16.4 MB/s) - ‘nips12raw_str602.tgz’ saved [12851423/12851423]\n","\n"]}],"source":["!wget https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz"]},{"cell_type":"markdown","source":["#### **A) Data Extraction**\n","\n","We need to uncompress this tgz file and extract the different text files within each of the subfolders, like so:"],"metadata":{"id":"KSZTp9edn0ym"}},{"cell_type":"code","source":["!tar -xzf nips12raw_str602.tgz"],"metadata":{"id":"HkvnO5VBn5GZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DATA_PATH = '/content/nipstxt'\n","print(os.listdir(DATA_PATH))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C5lhQiF7oAny","executionInfo":{"status":"ok","timestamp":1662835237596,"user_tz":360,"elapsed":444,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"8f62ea05-b9b1-4500-a933-3b2166f05a82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['nips05', 'idx', 'nips09', 'MATLAB_NOTES', 'orig', 'nips07', 'nips01', 'nips10', 'nips12', 'nips11', 'README_yann', 'nips02', 'nips03', 'nips06', 'nips04', 'nips00', 'RAW_DATA_NOTES', 'nips08']\n"]}]},{"cell_type":"code","source":["folders = [\"nips{0:02}\".format(i) for i in range(0,13)]\n","# Read all texts into a list.\n","papers = []\n","for folder in folders:\n","    file_names = os.listdir(DATA_PATH + '/' + folder )\n","    for file_name in file_names:\n","        with open(DATA_PATH + '/' + folder + '/' + file_name, encoding='utf-8', errors='ignore', mode='r+') as f:\n","            data = f.read()\n","        papers.append(data)\n","len(papers)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VHORRD_AoLO8","executionInfo":{"status":"ok","timestamp":1662835239465,"user_tz":360,"elapsed":288,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"dbf708b7-f0e1-439b-f7ad-1fdda4c30ae6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1740"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["**If using Jupyter notebooks/labs using this instead**"],"metadata":{"id":"UzPAZtyyqKZg"}},{"cell_type":"code","source":["\"\"\"\n","folders = [\"nips{0:02}\".format(i) for i in range(0,13)]\n","# Read all texts into a list.\n","papers = []\n","for folder in folders:\n","    file_names = os.listdir(DATA_PATH + folder)\n","    for file_name in file_names:\n","        with open(DATA_PATH + folder + '/' + file_name, encoding='utf-8', errors='ignore', mode='r+') as f:\n","            data = f.read()\n","        papers.append(data)\n","len(papers)\n","\"\"\""],"metadata":{"id":"lrU9i_XvqOR_","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1662746532007,"user_tz":360,"elapsed":8,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"51ce064a-204c-49a4-f2eb-e91d895c2367"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nfolders = [\"nips{0:02}\".format(i) for i in range(0,13)]\\n# Read all texts into a list.\\npapers = []\\nfor folder in folders:\\n    file_names = os.listdir(DATA_PATH + folder)\\n    for file_name in file_names:\\n        with open(DATA_PATH + folder + \\'/\\' + file_name, encoding=\\'utf-8\\', errors=\\'ignore\\', mode=\\'r+\\') as f:\\n            data = f.read()\\n        papers.append(data)\\nlen(papers)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["print(papers[0][:1000])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VlhVBNxBoOSg","executionInfo":{"status":"ok","timestamp":1662746532008,"user_tz":360,"elapsed":8,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"486dcfb2-57dd-4102-b24f-faba9c166d12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["387 \n","Neural Net and Traditional Classifiers  \n","William Y. Huang and Richard P. Lippmann \n","MIT Lincoln Laboratory \n","Lexington, MA 02173, USA \n","Abstract\n","Previous work on nets with continuous-valued inputs led to generative \n","procedures to construct convex decision regions with two-layer percepttons (one hidden \n","layer) and arbitrary decision regions with three-layer percepttons (two hidden layers). \n","Here we demonstrate that two-layer perceptton classifiers trained with back propagation \n","can form both convex and disjoint decision regions. Such classifiers are robust, train \n","rapidly, and provide good performance with simple decision regions. When complex \n","decision regions are required, however, convergence time can be excessively long and \n","performance is often no better than that of k-nearest neighbor classifiers. Three neural \n","net classifiers are presented that provide more rapid training under such situations. \n","Two use fixed weights in the first one or two layers and are similar to classifier\n"]}]},{"cell_type":"markdown","source":["## **2) Basic Text Preprocessing**\n","\n","We will do a separate normalize_corpus function here, because we don't need to do all the steps we normally would. This is going to save us some time in its execution."],"metadata":{"id":"YOJaEvsTrXPp"}},{"cell_type":"code","source":["%%time\n","\n","stop_words = nltk.corpus.stopwords.words('english')\n","wtk = nltk.tokenize.RegexpTokenizer(r'\\w+')\n","wnl = nltk.stem.wordnet.WordNetLemmatizer()\n","\n","def normalize_corpus(papers):\n","    norm_papers = []\n","    for paper in papers:\n","        paper = paper.lower() # set paper to lowercase\n","        paper_tokens = [token.strip() for token in wtk.tokenize(paper)] # tokenize paper and strip extra whitespaces\n","        paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]  # lemmatize tokens\n","        paper_tokens = [token for token in paper_tokens if len(token) > 1] # remove tokens shorter than 1 character or shorter\n","        paper_tokens = [token for token in paper_tokens if token not in stop_words] # remove stopwords\n","        paper_tokens = list(filter(None, paper_tokens))\n","        if paper_tokens:\n","            norm_papers.append(paper_tokens)\n","            \n","    return norm_papers\n","    \n","norm_papers = normalize_corpus(papers)\n","print(len(norm_papers))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fQty16iyrjYO","executionInfo":{"status":"ok","timestamp":1662835293051,"user_tz":360,"elapsed":37212,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"c903c80a-a856-4e42-8065-d1a2be1e35e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1740\n","CPU times: user 35.5 s, sys: 415 ms, total: 35.9 s\n","Wall time: 37.1 s\n"]}]},{"cell_type":"code","source":["print(norm_papers[0][:50])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"80oqa0q_so2E","executionInfo":{"status":"ok","timestamp":1662746567606,"user_tz":360,"elapsed":20,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"f6eafe9f-1a4f-4ba5-a063-fed98c47bfb1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['neural', 'net', 'traditional', 'classifier', 'william', 'huang', 'richard', 'lippmann', 'mit', 'lincoln', 'laboratory', 'lexington', 'usa', 'abstract', 'previous', 'work', 'net', 'continuous', 'valued', 'input', 'led', 'generative', 'procedure', 'construct', 'convex', 'decision', 'region', 'two', 'layer', 'percepttons', 'one', 'hidden', 'layer', 'arbitrary', 'decision', 'region', 'three', 'layer', 'percepttons', 'two', 'hidden', 'layer', 'demonstrate', 'two', 'layer', 'perceptton', 'classifier', 'trained', 'back', 'propagation']\n"]}]},{"cell_type":"markdown","source":["## 3) **Feature Engineering**\n","\n","Before we perform any sort of vectorization, we're going to narrow down our pool of words to more common n-grams; specifically bigrams that have occurred in the text at least 20 times. This is going to cut down on the number of words we need to vectorize."],"metadata":{"id":"BHmzLnLgw27M"}},{"cell_type":"code","source":["len(set(norm_papers[2]))*1740                                                                               # ~ vocab size of corpus"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SYj9tAklxSRN","executionInfo":{"status":"ok","timestamp":1662746567606,"user_tz":360,"elapsed":16,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"94d84124-e4a7-4c57-b9f7-4c6ea2784cdb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1839180"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["bigram = gensim.models.Phrases(norm_papers, min_count=20, threshold=20, delimiter=b'_')                     # higher threshold fewer phrases.\n","bigram_model = gensim.models.phrases.Phraser(bigram)\n","\n","print(bigram_model[norm_papers[0]][:50])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nbjAjkiEyGZr","executionInfo":{"status":"ok","timestamp":1662835314888,"user_tz":360,"elapsed":21852,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"6f1a555f-c44e-4536-e456-dd5b3ecbbf97"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['neural_net', 'traditional', 'classifier', 'william', 'huang', 'richard_lippmann', 'mit', 'lincoln_laboratory', 'lexington', 'usa_abstract', 'previous_work', 'net', 'continuous_valued', 'input', 'led', 'generative', 'procedure', 'construct', 'convex', 'decision_region', 'two', 'layer', 'percepttons', 'one', 'hidden_layer', 'arbitrary', 'decision_region', 'three', 'layer', 'percepttons', 'two', 'hidden_layer', 'demonstrate', 'two', 'layer', 'perceptton', 'classifier', 'trained', 'back_propagation', 'form', 'convex', 'disjoint', 'decision_region', 'classifier', 'robust', 'train', 'rapidly', 'provide', 'good', 'performance']\n"]}]},{"cell_type":"markdown","source":["> #### **A) Extract bigrams from full corpus to create a condensed vocab set of high frequency phrases**"],"metadata":{"id":"9j-Zj5eyyasp"}},{"cell_type":"code","source":["norm_corpus_bigrams = [bigram_model[doc] for doc in norm_papers]\n","\n","dictionary = gensim.corpora.Dictionary(norm_corpus_bigrams)                                                   # Create a dictionary representation of the documents\n","print('Sample word to number mappings:', list(dictionary.items())[:15])\n","print('Total Vocabulary Size:', len(dictionary))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xuZh08G6ynKU","executionInfo":{"status":"ok","timestamp":1662835324856,"user_tz":360,"elapsed":9984,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"b3138e5f-298d-4735-e53c-1bc01fa06af4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample word to number mappings: [(0, '1ooooo'), (1, '1st'), (2, '25oo'), (3, '2o00'), (4, '4ooo'), (5, '5oo'), (6, '64k'), (7, '7th'), (8, 'a2'), (9, 'aaditional'), (10, 'able'), (11, 'acase'), (12, 'adapting'), (13, 'addition'), (14, 'adjust')]\n","Total Vocabulary Size: 78892\n"]}]},{"cell_type":"markdown","source":["> #### **B) Let's further prune down our vocab set by removing words that occur in fewer than 20 documents or more than 60% of documents** "],"metadata":{"id":"YRIMxjdczZQ8"}},{"cell_type":"markdown","source":["**What is the logic behind this step?**"],"metadata":{"id":"xN9Tyjshzmd7"}},{"cell_type":"markdown","source":["We don't need to include very frequent or very infrequent words/bigrams; those typically don't add much value to the meaning of the text."],"metadata":{"id":"TFgp6FAEzq6W"}},{"cell_type":"code","source":["dictionary.filter_extremes(no_below=20, no_above=0.60)\n","print('Total Vocabulary Size:', len(dictionary))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VYM9JtFdzreH","executionInfo":{"status":"ok","timestamp":1662835325011,"user_tz":360,"elapsed":168,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"6de4c8c5-d1ae-43fd-bcf1-cb9f6f87c3a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total Vocabulary Size: 7756\n"]}]},{"cell_type":"markdown","source":["> #### **C) Bag of Words Vectorization**\n","\n","Great! Now we've got a much more reasonable vocab size, so that when we convert our words to sparse vectors we won't have so many dimensions. Let's create our bow corpus from our dictionary of bigrams."],"metadata":{"id":"Isv8rZq-bwgz"}},{"cell_type":"code","source":["bow_corpus = [dictionary.doc2bow(text) for text in norm_corpus_bigrams]\n","print(bow_corpus[1][:50])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oqOi5rH3cSwp","executionInfo":{"status":"ok","timestamp":1662835326403,"user_tz":360,"elapsed":1395,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"e2ccc6be-f6cd-40f5-d0f5-e17cd64802eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[(4, 1), (8, 1), (12, 1), (15, 1), (16, 1), (18, 3), (19, 1), (22, 2), (23, 1), (26, 1), (32, 1), (33, 1), (35, 1), (40, 2), (41, 1), (43, 1), (51, 2), (55, 2), (74, 2), (78, 1), (81, 1), (84, 2), (85, 2), (86, 1), (87, 3), (91, 1), (99, 2), (114, 4), (115, 2), (119, 1), (120, 3), (121, 1), (124, 4), (126, 1), (127, 1), (129, 2), (130, 1), (137, 1), (138, 1), (145, 1), (146, 1), (148, 1), (149, 1), (150, 16), (153, 2), (155, 1), (160, 1), (168, 8), (177, 1), (178, 12)]\n"]}]},{"cell_type":"markdown","source":["**What does each tuple represent here?**"],"metadata":{"id":"v3OnHoEqcYpd"}},{"cell_type":"markdown","source":["A word index and its frequency in document 01."],"metadata":{"id":"rPMinIQ_cbPn"}},{"cell_type":"code","source":["print([(dictionary[idx], freq) for idx, freq in bow_corpus[1][:50]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UhDkAkoccm4Q","executionInfo":{"status":"ok","timestamp":1662747150164,"user_tz":360,"elapsed":290,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"e359d700-fed0-40b0-ab91-446d7e06e0d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('able', 1), ('adjusted', 1), ('along', 1), ('alternative', 1), ('american_institute', 1), ('another', 3), ('appeared', 1), ('arbitrary', 2), ('architecture', 1), ('assigned', 1), ('author', 1), ('automatically', 1), ('averaged', 1), ('behavior', 2), ('belong', 1), ('better', 1), ('brain', 2), ('called', 2), ('comparison', 2), ('computing', 1), ('conference', 1), ('connection', 2), ('considered', 2), ('consists', 1), ('construct', 3), ('context', 1), ('definition', 2), ('density', 1), ('department', 3), ('depends', 1), ('desired', 4), ('detail', 1), ('determine', 1), ('determined', 2), ('developed', 1), ('disjoint', 1), ('divide', 1), ('enough', 1), ('entire', 1), ('eq', 1), ('equal', 1), ('estimate', 2), ('except', 1), ('expressed', 1), ('finite', 1), ('fixed', 12), ('formed', 1), ('forming', 1), ('four', 3), ('furthermore', 1)]\n"]}]},{"cell_type":"markdown","source":["## **4) Topic Modeling with Latent Semantic Indexing (LSI)**\n","\n","We begin with using latent semantic indexing to generate a topic model, we will set our total number of topics to 10 and then examine which words are most influential for each topic."],"metadata":{"id":"cKW4g_CadM64"}},{"cell_type":"code","source":["%%time\n","TOTAL_TOPICS = 10\n","lsi_bow = gensim.models.LsiModel(bow_corpus, id2word=dictionary, num_topics=TOTAL_TOPICS,\n","                                 onepass=True, chunksize=1740, power_iters=1000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i4J6zIxVdQrU","executionInfo":{"status":"ok","timestamp":1662835438719,"user_tz":360,"elapsed":197,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"ec49d06f-67f6-454a-9978-00560ed43cad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n","Wall time: 9.06 µs\n"]}]},{"cell_type":"markdown","source":["> #### **A) Print topics (top 20 words per 10 topics)**"],"metadata":{"id":"v_TTfsRihQ8P"}},{"cell_type":"code","source":["for topic_id, topic in lsi_bow.print_topics(num_topics=10, num_words=20):\n","    print('Topic #'+str(topic_id+1)+':')\n","    print(topic)\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vkKo5ZjtdgQs","executionInfo":{"status":"ok","timestamp":1662747621627,"user_tz":360,"elapsed":299,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"135d7d21-4264-4075-93a2-bfac6cb283ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Topic #1:\n","0.241*\"neuron\" + 0.187*\"image\" + 0.169*\"cell\" + 0.132*\"layer\" + 0.116*\"class\" + 0.114*\"signal\" + 0.113*\"response\" + 0.107*\"probability\" + 0.100*\"noise\" + 0.099*\"distribution\" + 0.099*\"node\" + 0.099*\"representation\" + 0.097*\"rule\" + 0.093*\"control\" + 0.091*\"rate\" + 0.086*\"stimulus\" + 0.083*\"sequence\" + 0.082*\"object\" + 0.082*\"architecture\" + 0.082*\"dynamic\"\n","\n","Topic #2:\n","0.534*\"neuron\" + 0.399*\"cell\" + 0.179*\"response\" + -0.167*\"image\" + 0.164*\"stimulus\" + -0.158*\"class\" + -0.118*\"classifier\" + 0.112*\"activity\" + 0.102*\"spike\" + 0.101*\"synaptic\" + -0.099*\"node\" + 0.094*\"firing\" + -0.093*\"word\" + 0.092*\"circuit\" + -0.090*\"probability\" + -0.085*\"classification\" + -0.079*\"sample\" + -0.078*\"distribution\" + 0.078*\"cortical\" + 0.077*\"signal\"\n","\n","Topic #3:\n","0.721*\"image\" + 0.216*\"object\" + -0.203*\"neuron\" + 0.148*\"cell\" + 0.143*\"visual\" + 0.110*\"pixel\" + 0.107*\"face\" + 0.106*\"motion\" + -0.088*\"rule\" + 0.082*\"response\" + -0.080*\"probability\" + 0.078*\"view\" + -0.073*\"node\" + 0.073*\"representation\" + -0.067*\"distribution\" + 0.066*\"location\" + -0.065*\"optimal\" + -0.063*\"action\" + 0.063*\"filter\" + -0.062*\"variable\"\n","\n","Topic #4:\n","0.642*\"cell\" + -0.564*\"neuron\" + -0.268*\"image\" + -0.099*\"chip\" + 0.088*\"response\" + 0.082*\"rat\" + -0.073*\"circuit\" + -0.073*\"object\" + 0.068*\"control\" + 0.065*\"action\" + -0.060*\"noise\" + 0.058*\"stimulus\" + -0.057*\"analog\" + 0.052*\"policy\" + 0.051*\"cue\" + 0.050*\"spatial\" + -0.050*\"synapse\" + 0.049*\"cortical\" + -0.049*\"bit\" + 0.049*\"probability\"\n","\n","Topic #5:\n","-0.406*\"word\" + -0.300*\"classifier\" + 0.231*\"control\" + -0.224*\"class\" + -0.198*\"layer\" + -0.192*\"recognition\" + 0.183*\"action\" + -0.180*\"node\" + -0.147*\"classification\" + -0.140*\"cell\" + 0.118*\"noise\" + 0.117*\"policy\" + 0.112*\"optimal\" + -0.109*\"character\" + 0.097*\"controller\" + 0.089*\"dynamic\" + 0.087*\"approximation\" + -0.087*\"net\" + 0.086*\"distribution\" + -0.086*\"hmm\"\n","\n","Topic #6:\n","0.314*\"word\" + 0.303*\"control\" + -0.235*\"class\" + -0.205*\"distribution\" + -0.190*\"cell\" + 0.165*\"action\" + -0.163*\"classifier\" + -0.146*\"image\" + -0.126*\"neuron\" + -0.121*\"probability\" + 0.119*\"architecture\" + 0.118*\"controller\" + -0.109*\"classification\" + 0.107*\"recognition\" + 0.105*\"sequence\" + 0.105*\"memory\" + 0.101*\"trajectory\" + 0.098*\"position\" + 0.096*\"representation\" + -0.095*\"sample\"\n","\n","Topic #7:\n","0.375*\"word\" + -0.371*\"rule\" + -0.348*\"node\" + 0.182*\"noise\" + 0.179*\"signal\" + -0.170*\"layer\" + 0.164*\"stimulus\" + 0.134*\"distribution\" + -0.133*\"action\" + 0.121*\"response\" + -0.109*\"classifier\" + 0.106*\"recognition\" + -0.105*\"object\" + 0.100*\"estimate\" + -0.100*\"memory\" + 0.096*\"speech\" + -0.093*\"tree\" + 0.092*\"spike\" + -0.092*\"cell\" + 0.092*\"frequency\"\n","\n","Topic #8:\n","-0.475*\"rule\" + 0.325*\"node\" + 0.296*\"circuit\" + 0.235*\"chip\" + 0.232*\"classifier\" + -0.189*\"neuron\" + 0.189*\"signal\" + 0.168*\"voltage\" + 0.136*\"analog\" + -0.113*\"word\" + 0.104*\"motion\" + -0.103*\"representation\" + -0.101*\"object\" + 0.100*\"control\" + 0.092*\"noise\" + -0.075*\"stimulus\" + 0.074*\"design\" + 0.073*\"channel\" + 0.070*\"transistor\" + -0.068*\"action\"\n","\n","Topic #9:\n","0.278*\"control\" + 0.250*\"action\" + 0.245*\"classifier\" + -0.243*\"node\" + 0.229*\"neuron\" + -0.222*\"rule\" + -0.201*\"signal\" + 0.195*\"class\" + 0.188*\"cell\" + -0.176*\"layer\" + -0.165*\"noise\" + -0.165*\"net\" + 0.160*\"word\" + 0.151*\"policy\" + 0.148*\"image\" + -0.131*\"hidden_unit\" + -0.121*\"representation\" + -0.115*\"stimulus\" + 0.111*\"controller\" + 0.107*\"classification\"\n","\n","Topic #10:\n","-0.487*\"rule\" + 0.228*\"stimulus\" + 0.221*\"object\" + -0.189*\"circuit\" + -0.189*\"image\" + -0.188*\"signal\" + 0.185*\"node\" + -0.183*\"cell\" + -0.183*\"chip\" + -0.179*\"noise\" + -0.154*\"word\" + -0.130*\"voltage\" + 0.128*\"response\" + 0.126*\"visual\" + 0.119*\"representation\" + -0.113*\"analog\" + 0.113*\"motion\" + 0.112*\"classifier\" + 0.106*\"neuron\" + 0.106*\"layer\"\n","\n"]}]},{"cell_type":"markdown","source":["**Like a correlation coefficient, the larger the associated weight, the stronger the influence of a word within a topic. But what does it mean for a topic to have words with positive and negative weights?**"],"metadata":{"id":"FKBuDXSLf9QP"}},{"cell_type":"markdown","source":["Can indicate two distrinct sub-topics (two directions) within one topic."],"metadata":{"id":"f6oJfEolgG4A"}},{"cell_type":"code","source":["for n in range(TOTAL_TOPICS):\n","    print('Topic #'+str(n+1)+':')\n","    print('='*50)\n","    d1 = []\n","    d2 = []\n","    for term, wt in lsi_bow.show_topic(n, topn=20):\n","        if wt >= 0:\n","            d1.append((term, round(wt, 3)))\n","        else:\n","            d2.append((term, round(wt, 3)))\n","\n","    print('Direction 1:', d1)\n","    print('-'*50)\n","    print('Direction 2:', d2)\n","    print('-'*50)\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jIHed9G7fp6o","executionInfo":{"status":"ok","timestamp":1662747848296,"user_tz":360,"elapsed":296,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"44edff75-78f6-443a-ce51-7803cdaca2c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Topic #1:\n","==================================================\n","Direction 1: [('neuron', 0.241), ('image', 0.187), ('cell', 0.169), ('layer', 0.132), ('class', 0.116), ('signal', 0.114), ('response', 0.113), ('probability', 0.107), ('noise', 0.1), ('distribution', 0.099), ('node', 0.099), ('representation', 0.099), ('rule', 0.097), ('control', 0.093), ('rate', 0.091), ('stimulus', 0.086), ('sequence', 0.083), ('object', 0.082), ('architecture', 0.082), ('dynamic', 0.082)]\n","--------------------------------------------------\n","Direction 2: []\n","--------------------------------------------------\n","\n","Topic #2:\n","==================================================\n","Direction 1: [('neuron', 0.534), ('cell', 0.399), ('response', 0.179), ('stimulus', 0.164), ('activity', 0.112), ('spike', 0.102), ('synaptic', 0.101), ('firing', 0.094), ('circuit', 0.092), ('cortical', 0.078), ('signal', 0.077)]\n","--------------------------------------------------\n","Direction 2: [('image', -0.167), ('class', -0.158), ('classifier', -0.118), ('node', -0.099), ('word', -0.093), ('probability', -0.09), ('classification', -0.085), ('sample', -0.079), ('distribution', -0.078)]\n","--------------------------------------------------\n","\n","Topic #3:\n","==================================================\n","Direction 1: [('image', 0.721), ('object', 0.216), ('cell', 0.148), ('visual', 0.143), ('pixel', 0.11), ('face', 0.107), ('motion', 0.106), ('response', 0.082), ('view', 0.078), ('representation', 0.073), ('location', 0.066), ('filter', 0.063)]\n","--------------------------------------------------\n","Direction 2: [('neuron', -0.203), ('rule', -0.088), ('probability', -0.08), ('node', -0.073), ('distribution', -0.067), ('optimal', -0.065), ('action', -0.063), ('variable', -0.062)]\n","--------------------------------------------------\n","\n","Topic #4:\n","==================================================\n","Direction 1: [('cell', 0.642), ('response', 0.088), ('rat', 0.082), ('control', 0.068), ('action', 0.065), ('stimulus', 0.058), ('policy', 0.052), ('cue', 0.051), ('spatial', 0.05), ('cortical', 0.049), ('probability', 0.049)]\n","--------------------------------------------------\n","Direction 2: [('neuron', -0.564), ('image', -0.268), ('chip', -0.099), ('circuit', -0.073), ('object', -0.073), ('noise', -0.06), ('analog', -0.057), ('synapse', -0.05), ('bit', -0.049)]\n","--------------------------------------------------\n","\n","Topic #5:\n","==================================================\n","Direction 1: [('control', 0.231), ('action', 0.183), ('noise', 0.118), ('policy', 0.117), ('optimal', 0.112), ('controller', 0.097), ('dynamic', 0.089), ('approximation', 0.087), ('distribution', 0.086)]\n","--------------------------------------------------\n","Direction 2: [('word', -0.406), ('classifier', -0.3), ('class', -0.224), ('layer', -0.198), ('recognition', -0.192), ('node', -0.18), ('classification', -0.147), ('cell', -0.14), ('character', -0.109), ('net', -0.087), ('hmm', -0.086)]\n","--------------------------------------------------\n","\n","Topic #6:\n","==================================================\n","Direction 1: [('word', 0.314), ('control', 0.303), ('action', 0.165), ('architecture', 0.119), ('controller', 0.118), ('recognition', 0.107), ('sequence', 0.105), ('memory', 0.105), ('trajectory', 0.101), ('position', 0.098), ('representation', 0.096)]\n","--------------------------------------------------\n","Direction 2: [('class', -0.235), ('distribution', -0.205), ('cell', -0.19), ('classifier', -0.163), ('image', -0.146), ('neuron', -0.126), ('probability', -0.121), ('classification', -0.109), ('sample', -0.095)]\n","--------------------------------------------------\n","\n","Topic #7:\n","==================================================\n","Direction 1: [('word', 0.375), ('noise', 0.182), ('signal', 0.179), ('stimulus', 0.164), ('distribution', 0.134), ('response', 0.121), ('recognition', 0.106), ('estimate', 0.1), ('speech', 0.096), ('spike', 0.092), ('frequency', 0.092)]\n","--------------------------------------------------\n","Direction 2: [('rule', -0.371), ('node', -0.348), ('layer', -0.17), ('action', -0.133), ('classifier', -0.109), ('object', -0.105), ('memory', -0.1), ('tree', -0.093), ('cell', -0.092)]\n","--------------------------------------------------\n","\n","Topic #8:\n","==================================================\n","Direction 1: [('node', 0.325), ('circuit', 0.296), ('chip', 0.235), ('classifier', 0.232), ('signal', 0.189), ('voltage', 0.168), ('analog', 0.136), ('motion', 0.104), ('control', 0.1), ('noise', 0.092), ('design', 0.074), ('channel', 0.073), ('transistor', 0.07)]\n","--------------------------------------------------\n","Direction 2: [('rule', -0.475), ('neuron', -0.189), ('word', -0.113), ('representation', -0.103), ('object', -0.101), ('stimulus', -0.075), ('action', -0.068)]\n","--------------------------------------------------\n","\n","Topic #9:\n","==================================================\n","Direction 1: [('control', 0.278), ('action', 0.25), ('classifier', 0.245), ('neuron', 0.229), ('class', 0.195), ('cell', 0.188), ('word', 0.16), ('policy', 0.151), ('image', 0.148), ('controller', 0.111), ('classification', 0.107)]\n","--------------------------------------------------\n","Direction 2: [('node', -0.243), ('rule', -0.222), ('signal', -0.201), ('layer', -0.176), ('noise', -0.165), ('net', -0.165), ('hidden_unit', -0.131), ('representation', -0.121), ('stimulus', -0.115)]\n","--------------------------------------------------\n","\n","Topic #10:\n","==================================================\n","Direction 1: [('stimulus', 0.228), ('object', 0.221), ('node', 0.185), ('response', 0.128), ('visual', 0.126), ('representation', 0.119), ('motion', 0.113), ('classifier', 0.112), ('neuron', 0.106), ('layer', 0.106)]\n","--------------------------------------------------\n","Direction 2: [('rule', -0.487), ('circuit', -0.189), ('image', -0.189), ('signal', -0.188), ('cell', -0.183), ('chip', -0.183), ('noise', -0.179), ('word', -0.154), ('voltage', -0.13), ('analog', -0.113)]\n","--------------------------------------------------\n","\n"]}]},{"cell_type":"markdown","source":["**Spend some time examining the different words amongst topics 1-10 and their 2 subtopics; what are some themes/possible topics that emerge?**"],"metadata":{"id":"Sua0a-vYgS1f"}},{"cell_type":"markdown","source":["Answer on own; topic 2 e.g., seems to be about neural activity and image classification"],"metadata":{"id":"r8hs0uJpgfAO"}},{"cell_type":"markdown","source":["> #### **B) Apply SVD to decompose our term-document matrix into term-topic, topic-topic, and topic-documnet matrices**"],"metadata":{"id":"pQi3GP2zhEuC"}},{"cell_type":"code","source":["term_topic = lsi_bow.projection.u\n","singular_values = lsi_bow.projection.s\n","topic_document = (gensim.matutils.corpus2dense(lsi_bow[bow_corpus], len(singular_values)).T / singular_values).T\n","term_topic.shape, singular_values.shape, topic_document.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YC7J-spAh4Mg","executionInfo":{"status":"ok","timestamp":1662748491112,"user_tz":360,"elapsed":1688,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"e276441d-9f3c-4abf-f1e9-18de8600a120"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gensim/matutils.py:502: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  result = np.column_stack(sparse2full(doc, num_terms) for doc in corpus)\n"]},{"output_type":"execute_result","data":{"text/plain":["((7706, 10), (10,), (10, 1740))"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["> #### **C) Transpose to Document Topic Matrix**"],"metadata":{"id":"oBXuuY_-iQ-1"}},{"cell_type":"code","source":["document_topics = pd.DataFrame(np.round(topic_document.T, 3), \n","                               columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n","document_topics.head(15)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"id":"Q73z0V0GiVPt","executionInfo":{"status":"ok","timestamp":1662748556761,"user_tz":360,"elapsed":267,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"f99cb216-ee38-40fe-e912-fa426b671880"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       T1     T2     T3     T4     T5     T6     T7     T8     T9    T10\n","0   0.041 -0.039 -0.018  0.002 -0.134 -0.038 -0.108  0.121  0.009  0.088\n","1   0.027 -0.012 -0.021 -0.001  0.001  0.015 -0.026 -0.015 -0.009  0.006\n","2   0.033 -0.018 -0.003  0.011  0.001  0.032 -0.012 -0.012 -0.017  0.010\n","3   0.032  0.030 -0.029 -0.054 -0.007  0.001 -0.013 -0.028  0.007 -0.025\n","4   0.025 -0.003 -0.016 -0.013  0.023 -0.003 -0.002  0.009 -0.002 -0.017\n","5   0.016  0.004 -0.013 -0.015  0.009  0.003 -0.009  0.001  0.009  0.005\n","6   0.030  0.059  0.012  0.080 -0.019 -0.030 -0.014 -0.005  0.011 -0.014\n","7   0.039 -0.016 -0.030  0.000 -0.019  0.077 -0.044 -0.015 -0.030  0.002\n","8   0.022  0.027 -0.001  0.028 -0.008 -0.014  0.004  0.005  0.011 -0.013\n","9   0.020  0.002 -0.004  0.009 -0.009 -0.004 -0.016 -0.001  0.010  0.008\n","10  0.021  0.016 -0.021 -0.030 -0.001 -0.001 -0.014 -0.025  0.004 -0.010\n","11  0.012  0.006 -0.011 -0.018  0.008 -0.004 -0.005  0.007  0.003 -0.010\n","12  0.018 -0.005 -0.016 -0.007  0.019 -0.010 -0.004 -0.005  0.007  0.002\n","13  0.026  0.008 -0.011 -0.025 -0.015  0.027 -0.028  0.091 -0.000 -0.064\n","14  0.008 -0.004 -0.005 -0.001 -0.001  0.002 -0.003  0.003 -0.005 -0.001"],"text/html":["\n","  <div id=\"df-ce1f2c30-f487-4007-af5f-13ea74520af0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>T1</th>\n","      <th>T2</th>\n","      <th>T3</th>\n","      <th>T4</th>\n","      <th>T5</th>\n","      <th>T6</th>\n","      <th>T7</th>\n","      <th>T8</th>\n","      <th>T9</th>\n","      <th>T10</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.041</td>\n","      <td>-0.039</td>\n","      <td>-0.018</td>\n","      <td>0.002</td>\n","      <td>-0.134</td>\n","      <td>-0.038</td>\n","      <td>-0.108</td>\n","      <td>0.121</td>\n","      <td>0.009</td>\n","      <td>0.088</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.027</td>\n","      <td>-0.012</td>\n","      <td>-0.021</td>\n","      <td>-0.001</td>\n","      <td>0.001</td>\n","      <td>0.015</td>\n","      <td>-0.026</td>\n","      <td>-0.015</td>\n","      <td>-0.009</td>\n","      <td>0.006</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.033</td>\n","      <td>-0.018</td>\n","      <td>-0.003</td>\n","      <td>0.011</td>\n","      <td>0.001</td>\n","      <td>0.032</td>\n","      <td>-0.012</td>\n","      <td>-0.012</td>\n","      <td>-0.017</td>\n","      <td>0.010</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.032</td>\n","      <td>0.030</td>\n","      <td>-0.029</td>\n","      <td>-0.054</td>\n","      <td>-0.007</td>\n","      <td>0.001</td>\n","      <td>-0.013</td>\n","      <td>-0.028</td>\n","      <td>0.007</td>\n","      <td>-0.025</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.025</td>\n","      <td>-0.003</td>\n","      <td>-0.016</td>\n","      <td>-0.013</td>\n","      <td>0.023</td>\n","      <td>-0.003</td>\n","      <td>-0.002</td>\n","      <td>0.009</td>\n","      <td>-0.002</td>\n","      <td>-0.017</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.016</td>\n","      <td>0.004</td>\n","      <td>-0.013</td>\n","      <td>-0.015</td>\n","      <td>0.009</td>\n","      <td>0.003</td>\n","      <td>-0.009</td>\n","      <td>0.001</td>\n","      <td>0.009</td>\n","      <td>0.005</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.030</td>\n","      <td>0.059</td>\n","      <td>0.012</td>\n","      <td>0.080</td>\n","      <td>-0.019</td>\n","      <td>-0.030</td>\n","      <td>-0.014</td>\n","      <td>-0.005</td>\n","      <td>0.011</td>\n","      <td>-0.014</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.039</td>\n","      <td>-0.016</td>\n","      <td>-0.030</td>\n","      <td>0.000</td>\n","      <td>-0.019</td>\n","      <td>0.077</td>\n","      <td>-0.044</td>\n","      <td>-0.015</td>\n","      <td>-0.030</td>\n","      <td>0.002</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.022</td>\n","      <td>0.027</td>\n","      <td>-0.001</td>\n","      <td>0.028</td>\n","      <td>-0.008</td>\n","      <td>-0.014</td>\n","      <td>0.004</td>\n","      <td>0.005</td>\n","      <td>0.011</td>\n","      <td>-0.013</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.020</td>\n","      <td>0.002</td>\n","      <td>-0.004</td>\n","      <td>0.009</td>\n","      <td>-0.009</td>\n","      <td>-0.004</td>\n","      <td>-0.016</td>\n","      <td>-0.001</td>\n","      <td>0.010</td>\n","      <td>0.008</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.021</td>\n","      <td>0.016</td>\n","      <td>-0.021</td>\n","      <td>-0.030</td>\n","      <td>-0.001</td>\n","      <td>-0.001</td>\n","      <td>-0.014</td>\n","      <td>-0.025</td>\n","      <td>0.004</td>\n","      <td>-0.010</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.012</td>\n","      <td>0.006</td>\n","      <td>-0.011</td>\n","      <td>-0.018</td>\n","      <td>0.008</td>\n","      <td>-0.004</td>\n","      <td>-0.005</td>\n","      <td>0.007</td>\n","      <td>0.003</td>\n","      <td>-0.010</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.018</td>\n","      <td>-0.005</td>\n","      <td>-0.016</td>\n","      <td>-0.007</td>\n","      <td>0.019</td>\n","      <td>-0.010</td>\n","      <td>-0.004</td>\n","      <td>-0.005</td>\n","      <td>0.007</td>\n","      <td>0.002</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.026</td>\n","      <td>0.008</td>\n","      <td>-0.011</td>\n","      <td>-0.025</td>\n","      <td>-0.015</td>\n","      <td>0.027</td>\n","      <td>-0.028</td>\n","      <td>0.091</td>\n","      <td>-0.000</td>\n","      <td>-0.064</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.008</td>\n","      <td>-0.004</td>\n","      <td>-0.005</td>\n","      <td>-0.001</td>\n","      <td>-0.001</td>\n","      <td>0.002</td>\n","      <td>-0.003</td>\n","      <td>0.003</td>\n","      <td>-0.005</td>\n","      <td>-0.001</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce1f2c30-f487-4007-af5f-13ea74520af0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ce1f2c30-f487-4007-af5f-13ea74520af0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ce1f2c30-f487-4007-af5f-13ea74520af0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["document_numbers = [8, 150, 200]\n","\n","for document_number in document_numbers:\n","    top_topics = list(document_topics.columns[np.argsort(-np.absolute(document_topics.iloc[document_number].values))[:3]])\n","    print('Document #'+str(document_number)+':')\n","    print('Dominant Topics (top 3):', top_topics)\n","    print('Paper Summary:')\n","    print(papers[document_number][:500])\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VmGZ-Xqjiuow","executionInfo":{"status":"ok","timestamp":1662748942389,"user_tz":360,"elapsed":261,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"d1681e6f-bf60-488c-e63f-02cb07aaf906"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Document #8:\n","Dominant Topics (top 3): ['T4', 'T2', 'T1']\n","Paper Summary:\n","242 \n","THE SIGMOID NONLINEARITY IN PREPYRIFORM CORTEX \n","Frank H. Eeckman \n","University of California, Berkeley, CA 94720 \n","ABSTRACT \n","We report a study bn the relationship between EEG amplitude values and unit \n","spike output in the prepyriform cortex of awake and motivated rats. This relationship \n","takes the form of a sigmoid curve, that describes normalized pulse-output for \n","normalized wave input. The curve is fitted using nonlinear regression and is \n","described by its slope and maximum value. \n","Measureme\n","\n","Document #150:\n","Dominant Topics (top 3): ['T8', 'T4', 'T2']\n","Paper Summary:\n","695 \n","ANALOG IMPLEMENTATION OF SHUNTING \n","NEURAL NETWORKS \n","Bahram Nabet, Robert B. Darling, and Robert B. Pinter \n","Department of Electrical Engineering, FT-10 \n","University of Washington \n","Seattle, WA 98195 \n","ABSTRACT \n","An extremely compact, all analog and fully parallel implementa- \n","tion of a class of shunting recurrent neural networks that is ap- \n","plicable to a wide variety of FET-based integration technologies is \n","proposed. While the contrast enhancement, data compression, and \n","adaptation to mean inp\n","\n","Document #200:\n","Dominant Topics (top 3): ['T9', 'T6', 'T1']\n","Paper Summary:\n","524 Fahlman and Lebiere \n","The Cascade-Correlation Learning Architecture \n","Scott E. Fahlman and Christian Lebiere \n","School of Computer Science \n","Carnegie-Mellon University \n","Pittsburgh, PA 15213 \n","ABSTRACT \n","Cascade-Correlation is a new architecture and supervised learning algo- \n","rithm for artificial neural networks. Instead of just adjusting the weights \n","in a network of fixed topology, Cascade-Correlation begins with a min- \n","imal network, then automatically trains and adds new hidden units one \n","by one,\n","\n"]}]},{"cell_type":"markdown","source":["**Examine a sample of three different documents. Based on the information provided in our *document summary*, do the top 3 topics for each of these sampled documents make sense? Refer back to the list of top 20 words for each topic.**"],"metadata":{"id":"dzKHwMWsjJtn"}},{"cell_type":"markdown","source":[],"metadata":{"id":"qATFCnk9sLgM"}},{"cell_type":"markdown","source":["## **5) Topic Modeling with Latent Dirichlet Allocation (LDA)**"],"metadata":{"id":"5oyMyhYnjVZ3"}},{"cell_type":"code","source":["%%time\n","lda_model = gensim.models.LdaModel(corpus=bow_corpus, id2word=dictionary, chunksize=1740, \n","                                   alpha='auto', eta='auto', random_state=42,\n","                                   iterations=500, num_topics=TOTAL_TOPICS, \n","                                   passes=20, eval_every=None)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R8EAAj7AsI2V","executionInfo":{"status":"ok","timestamp":1662751229120,"user_tz":360,"elapsed":97249,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"5e8cd1aa-e6db-46a4-8e5d-ae95adf7440d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 1min 36s, sys: 2.39 s, total: 1min 38s\n","Wall time: 1min 36s\n"]}]},{"cell_type":"markdown","source":["> #### **A) Print topics, topics = 10**"],"metadata":{"id":"rymHHiiO00Bj"}},{"cell_type":"code","source":["for topic_id, topic in lda_model.print_topics(num_topics=10, num_words=20):\n","    print('Topic #'+str(topic_id+1)+':')\n","    print(topic)\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kc55oSR9sOW3","executionInfo":{"status":"ok","timestamp":1662751347605,"user_tz":360,"elapsed":280,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"3e4c73b0-0394-4d9c-a1e5-08f06ded27fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Topic #1:\n","0.023*\"neuron\" + 0.020*\"cell\" + 0.009*\"response\" + 0.008*\"activity\" + 0.007*\"stimulus\" + 0.006*\"synaptic\" + 0.005*\"circuit\" + 0.005*\"connection\" + 0.004*\"cortical\" + 0.004*\"firing\" + 0.004*\"layer\" + 0.004*\"synapsis\" + 0.004*\"spike\" + 0.004*\"voltage\" + 0.004*\"signal\" + 0.004*\"cortex\" + 0.003*\"simulation\" + 0.003*\"frequency\" + 0.003*\"chip\" + 0.003*\"mechanism\"\n","\n","Topic #2:\n","0.009*\"distribution\" + 0.008*\"variable\" + 0.007*\"probability\" + 0.006*\"prior\" + 0.006*\"gaussian\" + 0.006*\"estimate\" + 0.006*\"mixture\" + 0.005*\"approximation\" + 0.005*\"density\" + 0.005*\"bayesian\" + 0.004*\"sample\" + 0.004*\"matrix\" + 0.004*\"likelihood\" + 0.004*\"estimation\" + 0.004*\"component\" + 0.003*\"log\" + 0.003*\"variance\" + 0.003*\"noise\" + 0.003*\"posterior\" + 0.003*\"em\"\n","\n","Topic #3:\n","0.012*\"classifier\" + 0.012*\"class\" + 0.010*\"classification\" + 0.006*\"rule\" + 0.005*\"test\" + 0.005*\"kernel\" + 0.004*\"training_set\" + 0.004*\"tree\" + 0.004*\"prediction\" + 0.004*\"machine\" + 0.003*\"table\" + 0.003*\"probability\" + 0.003*\"representation\" + 0.003*\"sample\" + 0.003*\"instance\" + 0.003*\"query\" + 0.003*\"distance\" + 0.003*\"trained\" + 0.002*\"best\" + 0.002*\"node\"\n","\n","Topic #4:\n","0.009*\"memory\" + 0.009*\"bit\" + 0.008*\"circuit\" + 0.008*\"chip\" + 0.007*\"node\" + 0.006*\"analog\" + 0.006*\"threshold\" + 0.005*\"capacity\" + 0.005*\"graph\" + 0.005*\"processor\" + 0.005*\"element\" + 0.004*\"gate\" + 0.004*\"computation\" + 0.004*\"implementation\" + 0.004*\"connection\" + 0.004*\"operation\" + 0.004*\"parallel\" + 0.003*\"design\" + 0.003*\"code\" + 0.003*\"matrix\"\n","\n","Topic #5:\n","0.015*\"word\" + 0.011*\"recognition\" + 0.009*\"speech\" + 0.008*\"sequence\" + 0.006*\"context\" + 0.006*\"architecture\" + 0.006*\"trained\" + 0.005*\"layer\" + 0.005*\"character\" + 0.005*\"recurrent\" + 0.005*\"speaker\" + 0.005*\"net\" + 0.004*\"language\" + 0.004*\"module\" + 0.004*\"letter\" + 0.004*\"frame\" + 0.004*\"activation\" + 0.004*\"node\" + 0.004*\"representation\" + 0.004*\"hmm\"\n","\n","Topic #6:\n","0.033*\"image\" + 0.014*\"object\" + 0.010*\"visual\" + 0.008*\"motion\" + 0.007*\"pixel\" + 0.006*\"representation\" + 0.005*\"face\" + 0.005*\"location\" + 0.005*\"view\" + 0.005*\"response\" + 0.004*\"stimulus\" + 0.004*\"position\" + 0.004*\"spatial\" + 0.004*\"direction\" + 0.004*\"region\" + 0.004*\"target\" + 0.004*\"layer\" + 0.004*\"filter\" + 0.004*\"field\" + 0.004*\"map\"\n","\n","Topic #7:\n","0.019*\"control\" + 0.008*\"controller\" + 0.007*\"trajectory\" + 0.007*\"position\" + 0.006*\"movement\" + 0.006*\"robot\" + 0.006*\"motor\" + 0.005*\"dynamic\" + 0.004*\"direction\" + 0.004*\"environment\" + 0.004*\"forward\" + 0.004*\"arm\" + 0.004*\"expert\" + 0.004*\"target\" + 0.004*\"behavior\" + 0.003*\"move\" + 0.003*\"hand\" + 0.003*\"goal\" + 0.003*\"mapping\" + 0.003*\"adaptive\"\n","\n","Topic #8:\n","0.007*\"action\" + 0.006*\"optimal\" + 0.005*\"policy\" + 0.005*\"let\" + 0.005*\"bound\" + 0.004*\"rate\" + 0.004*\"approximation\" + 0.004*\"convergence\" + 0.004*\"probability\" + 0.004*\"theorem\" + 0.004*\"reinforcement_learning\" + 0.003*\"distribution\" + 0.003*\"class\" + 0.003*\"estimate\" + 0.003*\"control\" + 0.003*\"sample\" + 0.003*\"machine\" + 0.003*\"solution\" + 0.003*\"loss\" + 0.002*\"sequence\"\n","\n","Topic #9:\n","0.011*\"hidden_unit\" + 0.009*\"layer\" + 0.007*\"net\" + 0.006*\"node\" + 0.005*\"back_propagation\" + 0.004*\"trained\" + 0.004*\"training_set\" + 0.004*\"architecture\" + 0.004*\"hidden_layer\" + 0.004*\"region\" + 0.003*\"representation\" + 0.003*\"solution\" + 0.003*\"rule\" + 0.003*\"map\" + 0.003*\"generalization\" + 0.003*\"hidden\" + 0.003*\"connection\" + 0.003*\"activation\" + 0.003*\"cluster\" + 0.003*\"local\"\n","\n","Topic #10:\n","0.012*\"signal\" + 0.011*\"noise\" + 0.010*\"neuron\" + 0.008*\"dynamic\" + 0.006*\"matrix\" + 0.004*\"solution\" + 0.004*\"filter\" + 0.004*\"source\" + 0.004*\"eq\" + 0.004*\"attractor\" + 0.004*\"component\" + 0.004*\"rate\" + 0.004*\"rule\" + 0.003*\"fixed_point\" + 0.003*\"nonlinear\" + 0.003*\"distribution\" + 0.003*\"spike\" + 0.003*\"correlation\" + 0.003*\"ica\" + 0.003*\"phase\"\n","\n"]}]},{"cell_type":"markdown","source":["**What is a key difference in the weights produced using LSI vs LDA?**"],"metadata":{"id":"O6rLFln_tFX6"}},{"cell_type":"markdown","source":["LSI contain negative weights, LDA does not -- makes the LDA weights easier to interpret."],"metadata":{"id":"kpaUsrs6tJr9"}},{"cell_type":"markdown","source":["> #### **B) Topic Coherenence Scores**\n","\n","Let's now get an idea of how our topic model is performing by computing the perplexity and the coherence scores ($C_v$ and UMass)."],"metadata":{"id":"ujVDR9wU087K"}},{"cell_type":"code","source":["cv_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n","                                                      texts=norm_corpus_bigrams,\n","                                                      dictionary=dictionary, \n","                                                      coherence='c_v')\n","avg_coherence_cv = cv_coherence_model_lda.get_coherence()\n","\n","umass_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n","                                                         texts=norm_corpus_bigrams,\n","                                                         dictionary=dictionary, \n","                                                         coherence='u_mass')\n","avg_coherence_umass = umass_coherence_model_lda.get_coherence()\n","\n","perplexity = lda_model.log_perplexity(bow_corpus)\n","\n","print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n","print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n","print('Model Perplexity:', perplexity)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WO_UYI7N185g","executionInfo":{"status":"ok","timestamp":1662753866259,"user_tz":360,"elapsed":60033,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"3d629cc9-d320-4a85-9a85-229048b4c4d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Avg. Coherence Score (Cv): 0.5024377489290612\n","Avg. Coherence Score (UMass): -1.1587366536698354\n","Model Perplexity: -7.861088487128816\n"]}]},{"cell_type":"markdown","source":["> #### **C) (On your own) Try out a Different LDA Model Implementation from MALLET**\n","\n","For the sake of time, try out a different LDA model implementation from a library called MALLET (MAchine Learning for LanguagE Toolkit) -- they really forced that acronym. It's worth exploring different pretrained models because different models will work better in different situations. Run through the provided code and report back on your findings."],"metadata":{"id":"brXeqs3XrfYs"}},{"cell_type":"code","source":["!wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip            # download mallet zip file\n","!unzip -q mallet-2.0.8.zip                                        # unzip compressed files"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_zQSc9aBsD35","executionInfo":{"status":"ok","timestamp":1662835121527,"user_tz":360,"elapsed":2160,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"cd290e22-f1f1-4aa8-f500-673dd2f7b9ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-09-10 18:38:39--  http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n","Resolving mallet.cs.umass.edu (mallet.cs.umass.edu)... 128.119.246.70\n","Connecting to mallet.cs.umass.edu (mallet.cs.umass.edu)|128.119.246.70|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://mallet.cs.umass.edu/dist/mallet-2.0.8.zip [following]\n","--2022-09-10 18:38:39--  https://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n","Connecting to mallet.cs.umass.edu (mallet.cs.umass.edu)|128.119.246.70|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 16184794 (15M) [application/zip]\n","Saving to: ‘mallet-2.0.8.zip’\n","\n","mallet-2.0.8.zip    100%[===================>]  15.43M  16.7MB/s    in 0.9s    \n","\n","2022-09-10 18:38:40 (16.7 MB/s) - ‘mallet-2.0.8.zip’ saved [16184794/16184794]\n","\n"]}]},{"cell_type":"code","source":["MALLET_PATH = 'mallet-2.0.8/bin/mallet'                                                               # set path to mallet models\n","lda_mallet = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, corpus=bow_corpus,             # set lda model parameters\n","                                              num_topics=TOTAL_TOPICS, id2word=dictionary,\n","                                              iterations=500, workers=16)"],"metadata":{"id":"ol54oiUJsOAl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["topics = [[(term, round(wt, 3)) \n","               for term, wt in lda_mallet.show_topic(n, topn=20)]                                     # save topics as list, round weights to 3 decimanls, top 20 words per topic\n","                   for n in range(0, TOTAL_TOPICS)]\n","\n","for idx, topic in enumerate(topics):                                                                  # print each topic with their top 20 terms\n","    print('Topic #'+str(idx+1)+':')\n","    print([term for term, wt in topic])\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YYGQzrcysXhF","executionInfo":{"status":"ok","timestamp":1662835600158,"user_tz":360,"elapsed":8,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"8eb970a2-1b22-49b8-e7c4-26c935ff9f5f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Topic #1:\n","['training', 'class', 'classification', 'word', 'classifier', 'recognition', 'feature', 'pattern', 'vector', 'speech', 'trained', 'sequence', 'character', 'cluster', 'context', 'hmm', 'experiment', 'probability', 'test', 'rbf']\n","\n","Topic #2:\n","['training', 'tree', 'test', 'experiment', 'search', 'prediction', 'size', 'table', 'graph', 'training_set', 'feature', 'node', 'technique', 'average', 'measure', 'random', 'machine', 'run', 'selection', 'instance']\n","\n","Topic #3:\n","['dynamic', 'equation', 'state', 'memory', 'neuron', 'vector', 'pattern', 'matrix', 'solution', 'energy', 'phase', 'eq', 'noise', 'code', 'capacity', 'attractor', 'fig', 'correlation', 'fixed_point', 'rule']\n","\n","Topic #4:\n","['signal', 'circuit', 'current', 'chip', 'neuron', 'analog', 'voltage', 'channel', 'noise', 'source', 'bit', 'neural', 'implementation', 'filter', 'design', 'processor', 'computation', 'frequency', 'gain', 'parallel']\n","\n","Topic #5:\n","['linear', 'vector', 'class', 'convergence', 'bound', 'theorem', 'optimal', 'approximation', 'defined', 'theory', 'size', 'xi', 'constant', 'condition', 'complexity', 'probability', 'threshold', 'gradient', 'define', 'property']\n","\n","Topic #6:\n","['distribution', 'estimate', 'gaussian', 'variable', 'prior', 'noise', 'variance', 'mixture', 'density', 'probability', 'approximation', 'sample', 'component', 'estimation', 'bayesian', 'linear', 'prediction', 'matrix', 'regression', 'equation']\n","\n","Topic #7:\n","['cell', 'neuron', 'response', 'stimulus', 'activity', 'pattern', 'spike', 'effect', 'synaptic', 'neural', 'cortical', 'et_al', 'firing', 'brain', 'signal', 'cortex', 'frequency', 'connection', 'mechanism', 'change']\n","\n","Topic #8:\n","['unit', 'layer', 'training', 'rule', 'net', 'hidden_unit', 'architecture', 'node', 'pattern', 'activation', 'representation', 'task', 'trained', 'structure', 'recurrent', 'hidden_layer', 'sequence', 'back_propagation', 'connection', 'module']\n","\n","Topic #9:\n","['image', 'object', 'feature', 'motion', 'visual', 'representation', 'location', 'map', 'direction', 'pixel', 'position', 'region', 'field', 'local', 'view', 'face', 'target', 'surface', 'human', 'filter']\n","\n","Topic #10:\n","['state', 'control', 'action', 'step', 'trajectory', 'task', 'environment', 'policy', 'controller', 'optimal', 'reinforcement_learning', 'dynamic', 'change', 'robot', 'goal', 'adaptive', 'path', 'position', 'forward', 'transition']\n","\n"]}]},{"cell_type":"code","source":["cv_coherence_model_lda_mallet = gensim.models.CoherenceModel(model=lda_mallet, corpus=bow_corpus, \n","                                                             texts=norm_corpus_bigrams,\n","                                                             dictionary=dictionary, \n","                                                             coherence='c_v')\n","avg_coherence_cv = cv_coherence_model_lda_mallet.get_coherence()\n","\n","umass_coherence_model_lda_mallet = gensim.models.CoherenceModel(model=lda_mallet, corpus=bow_corpus, \n","                                                                texts=norm_corpus_bigrams,\n","                                                                dictionary=dictionary,  \n","                                                                coherence='u_mass')\n","avg_coherence_umass = umass_coherence_model_lda_mallet.get_coherence()\n","\n","# from STDOUT: <500> LL/token: -8.53533\n","perplexity = -8.53533\n","print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n","print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n","print('Model Perplexity:', perplexity)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hBpWmWXZt662","executionInfo":{"status":"ok","timestamp":1662835685124,"user_tz":360,"elapsed":68568,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"43bcbe3a-674f-48a1-e9ec-2815311fe493"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Avg. Coherence Score (Cv): 0.5031632844310924\n","Avg. Coherence Score (UMass): -1.070707076010317\n","Model Perplexity: -8.53533\n"]}]},{"cell_type":"markdown","source":["**How do the metrics of topic model quality differ between the basic gensim implementation and the mallet implementation? Which model appeared to perform better in this case?**"],"metadata":{"id":"_StHlj0At-nH"}},{"cell_type":"markdown","source":[],"metadata":{"id":"M1_VIvNPuN6M"}},{"cell_type":"markdown","source":["## **6) Parameter Tuning a Topic Model**\n","\n","Parameter tuning for an unsupervised text mining technique like topic modeling is a little odd, since we don't have direct evaluation metrics. But, we can use our topic coherence scores to try and find an optimal number of topics, where by we have the fewest topics (to maximize simplicity) for the highest coherence score (to maximize topic quality). We will examine this iteratively to determine the optimal number of topics; and will produce a visualization to help guide our conclusion.\n"],"metadata":{"id":"HZ4_k23iuOqv"}},{"cell_type":"code","source":["from tqdm import tqdm"],"metadata":{"id":"r_I_p93MvQaC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def topic_model_coherence_generator(corpus, texts, dictionary, \n","                                    start_topic_count=2, end_topic_count=10, step=1,\n","                                    cpus=1):\n","    \n","    models = []\n","    coherence_scores = []\n","    for topic_nums in tqdm(range(start_topic_count, end_topic_count+1, step)):\n","        mallet_lda_model = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, corpus=corpus,\n","                                                            num_topics=topic_nums, id2word=dictionary,\n","                                                            iterations=500, workers=cpus)\n","        cv_coherence_model_mallet_lda = gensim.models.CoherenceModel(model=mallet_lda_model, corpus=corpus, \n","                                                                     texts=texts, dictionary=dictionary, \n","                                                                     coherence='c_v')\n","        coherence_score = cv_coherence_model_mallet_lda.get_coherence()\n","        coherence_scores.append(coherence_score)\n","        models.append(mallet_lda_model)\n","    \n","    return models, coherence_scores"],"metadata":{"id":"1HMvk0BkvKbv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lda_models, coherence_scores = topic_model_coherence_generator(corpus=bow_corpus, texts=norm_corpus_bigrams,\n","                                                               dictionary=dictionary, start_topic_count=10,\n","                                                               end_topic_count=12, step=1, cpus=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j-gFh7MwvZQx","executionInfo":{"status":"ok","timestamp":1662839701230,"user_tz":360,"elapsed":546186,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"7a9c4871-c7d2-470a-b39c-58566bf74bb9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 3/3 [09:06<00:00, 182.00s/it]\n"]}]},{"cell_type":"markdown","source":["> #### **A) (On your own) Evaluate a larger number of topics**\n","\n","Go back through the previous code on your own and train topic models on a larger range of topics to try and find an optimal amount. We examined a narrow range in class, so we may not have found the best number of topics. Running this will take some time, and the larger your range the more time it will take to run.\n","\n","Report back below on what you found the best number of topics to be after rerunning this analysis."],"metadata":{"id":"0s7jV1HV6Kk9"}},{"cell_type":"markdown","source":[],"metadata":{"id":"iEJEBnKt6rJ1"}},{"cell_type":"markdown","source":["> #### **B) Produce table of topic numbers by coherence scores; then plot**"],"metadata":{"id":"LiyJFZ7-0S1X"}},{"cell_type":"code","source":["coherence_scores"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YlutQPfu-474","executionInfo":{"status":"ok","timestamp":1662839924805,"user_tz":360,"elapsed":2,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"0e1525b3-06be-463d-9295-f44c6bfe13d8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.5260681844987625, 0.5164835418968532, 0.5213157294626155]"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["coherence_df = pd.DataFrame({'Number of Topics': range(10, 13, 1),\n","                             'Coherence Score': np.round(coherence_scores, 4)})\n","coherence_df.sort_values(by=['Coherence Score'], ascending=False).head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"PallcNEWz_Om","executionInfo":{"status":"ok","timestamp":1662840516397,"user_tz":360,"elapsed":142,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"24677114-2fc8-410d-9cf5-86ddb45536d0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Number of Topics  Coherence Score\n","0                10           0.5261\n","2                12           0.5213\n","1                11           0.5165"],"text/html":["\n","  <div id=\"df-ca937c17-3dfc-41bf-81c5-cf71beae37d8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Number of Topics</th>\n","      <th>Coherence Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10</td>\n","      <td>0.5261</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>12</td>\n","      <td>0.5213</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11</td>\n","      <td>0.5165</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca937c17-3dfc-41bf-81c5-cf71beae37d8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ca937c17-3dfc-41bf-81c5-cf71beae37d8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ca937c17-3dfc-41bf-81c5-cf71beae37d8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["plt.style.use('fivethirtyeight')\n","%matplotlib inline\n","\n","x_ax = range(10,13,1)                                                                   # Adjust the range based on the number/range of topics you chose\n","y_ax = coherence_scores\n","plt.figure(figsize=(12, 6))\n","plt.plot(x_ax, y_ax, c='r')\n","plt.axhline(y=0.525, c='k', linestyle='--', linewidth=2)\n","plt.rcParams['figure.facecolor'] = 'white'\n","xl = plt.xlabel('Number of Topics')\n","yl = plt.ylabel('Coherence Score')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388},"id":"JCYgkcYA3YPt","executionInfo":{"status":"ok","timestamp":1662840423090,"user_tz":360,"elapsed":633,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"83e35c36-daa1-4e8b-bd16-cec6aac6da49"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 864x432 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAy8AAAFzCAYAAAA3/jaVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXhU9dnG8e8zk5kkMxFUcEF2lWpdCnbRqq2tLWFVUAEBUaBIWVx4tVoUUetSte64iygouLBYURQQQlvspi3aWitajVIjKCouLDOTZJLM7/0jQ5oBIgNkcmaS+3NdczHz/M4k9xxAeXLOeY455xAREREREcl2Pq8DiIiIiIiIpEPNi4iIiIiI5AQ1LyIiIiIikhPUvIiIiIiISE5Q8yIiIiIiIjkhz+sAmbRp0yaNUhMRERERyUGtW7e2bWs68iIiIiIiIjlBzYuIiIiIiOQENS9NpLS01OsIzZL2a+PTPs0M7dfGp32aGdqvjU/7tPFpn2ZGLuxXNS8iIiIiIpIT1LyIiIiIiEhOUPMiIiIiIiI5Qc2LiIiIiIjkBDUvIiIiIiKSE9S8iIiIiIhITlDzIiIiIiIiOUHNi4iIiIiI5AQ1LyIiIiIikhPUvIiIiIiISE5osubFzPqY2Ttm9p6ZXb6D9dFmtsHMXk8+xibrPczsZTNbbWZvmNnQeu8xM7vBzN41s7fNbFJTfZ7d4f/737ENG7yOISIiIiKSk/Ka4puYmR+4DygG1gGrzGyRc+6tbTad55y7YJtaDBjpnCs1s4OA18xsmXNuIzAa6Agc7pxLmNn+mf0ku6/gvfcIjx9PYt99iS1YQKJbN68jiYiIiIjklKY68nIs8J5zbo1zLg7MBQam80bn3LvOudLk84+Bz4D9kssTgeucc4nk+meNnrwR2Cef0O3ii7HNm/F/8AHh4mL8f/2r17FERERERHJKUzUv7YG19V6vS9a2NSh5atjTZtZx20UzOxYIAu8nS4cAQ83sVTNbamZZeTgj/847yf/kk7rXvo0bCZ92GoGnn/YwlYiIiIhIbjHnXOa/idlgoI9zbut1LOcAx9U/RczM2gAR51ylmY0HhjrnflJvvR2wEhjlnHslWYsAv3LO3W5mZwAXO+d+uPU9mzZtqvtwpaWlGf2MX8eqquh84420feGF7dbWnXcen4weDWZNH0xEREREJIt0q3dpRevWrbf7B3JTNS/HA9c453onX08BcM7d1MD2fuBL51zr5OtW1DYuNzrnnq633X+Avs65/5qZARu3vgdSmxevlb77Lkc9+ywFN9643Vp85EjKb78dAgEPkuW20tLSlD/ksue0TzND+7XxaZ9mhvZr49M+bXzap5mRbft1R81LU502tgroZmZdzSwIDAMW1d8geWRlqwHA28l6EFgIzK7fuCQ9C5ycfP4j4N0MZG8cZlROnkzswQdx2zQpwdmzCQ0dCps3exRORERERCT7NUnz4pyrBi4AllHblMx3zq02s+vMbEBys0nJccj/AiZRO0kM4EzgJGB0vTHKPZJrv6H2Opl/AzcBY5vi8+yJqmHDiP72t7hWrVLqgd//nqI+fbCPPvIomYiIiIhIdmuSUckAzrklwJJtalfXez4FmLKD9z0OPN7A19wI9G/cpJlXc9JJRJYvJzxkCL61/5tj4H/rLYp69iQ6bx6Jb33Lw4QiIiIiItmnyW5SKakShx9OZMUKqo85JqXuW7+eon79yCsp8SiZiIiIiEh2UvPiIXfAAURfeIGqfv1S6haJEBo2jMCjj3qSS0REREQkG6l58Vo4TGzOHCrHj08pW00NoYsuIv+aayCR8CabiIiIiEgWUfOSDfx+Km6+mfKbbsJtc7+XgmnTKDz3XKio8CiciIiIiEh2UPOSReITJxKbMwdXWJhSDy5cSPi007AvvvAomYiIiIiI99S8ZJnqU04h+sILJPbbL6We98orhHv1wrdmjUfJRERERES8peYlC9V85ztESkqo+cY3Uur+998n3LMn/r/9zaNkIiIiIiLeUfOSpVyXLkSWL6f6xBNT6r4vvyQ8YAB5zz7rUTIREREREW+oeclme+9N9JlniJ95ZkrZKisJjx5N8O67wTmPwomIiIiINC01L9kuP5/y6dOp+OUvt1sqvPpqCi65BKqrPQgmIiIiItK01LzkAjMqp04ldu+9uLy8lKX8mTMJnXUWRCIehRMRERERaRpqXnJI1dlnE336aVyrVin1wPLlFPXrh61f71EyEREREZHMU/OSY2p+/GMiL75IokOHlLr/jTco6tkT3+rVHiUTEREREcksNS85KHHEEbWjlLt3T6n7PvqIoj59yPvDHzxKJiIiIiKSOWpecpRr147I4sVU9e6dUrctWwgNGUJgzhyPkomIiIiIZIaal1xWVETsiSeoPPfclLJVVxO68ELyf/1rjVIWERERkWZDzUuuy8uj4rbbKL/++u2WCm67jcJx46Cy0oNgIiIiIiKNS81Lc2BG/MILiT72GK6gIGUpuGAB4dNPx776yqNwIiIiIiKNQ81LM1I9cCDRRYtItGmTUs/7618J9+6NffCBN8FERERERBqBmpdmpubYY4muWEHNIYek1P3vvktRcTH+117zKJmIiIiIyJ5R89IMJbp2JVpSQvXxx6fUfRs2ED7lFPKef96jZCIiIiIiu0/NSzPl9t2X6MKFxAcNSqlbeTmhkSMJ3n+/R8lERERERHaPmpfmrKCA8hkzqPjFL1LK5hyFV1xBwWWXQU2NR+FERERERHaNmpfmzuej8uqrid11F87vT1nKnz6d0NlnQzTqUTgRERERkfSpeWkhqkaNIjZ/Pq6oKKUeWLqU8CmnYJ9+6lEyEREREZE0Oeea7WPjxo1u6wPY7jFt2rS69WnTpu1wm62P+l+re/fuDW43atSouu1Wrlz5tV9z5cqVdduOGjWqwe26d+/udvZZduczuXqPbwcCzeIzNcffJ30mfSZ9Jn0mfSZ9Jn2m1Mfhhx/e7D5TNvw+rVq1Kis+09bHjv59ryMvUquqyusEIiIiIiJfy5xzXmfImE2bNmXNhystLaVbt25ex/ifzZsJ/exnBH73u5SyCwQov/tuqoYP9yjYrsm6/doMaJ9mhvZr49M+zQzt18anfdr4tE8zI9v2a+vWrW3bmo68tFStWhGbO5f4qFEpZauqIjRxIvk33wzNuLEVERERkdyj5qUlCwQonzaN8muu2W6p4KabKDzvPIjHmz6XiIiIiMgOqHlp6cyIX3QRsZkzccFgylLwqacIDx4MGzd6FE5ERERE5H/UvAgAVWecQfS550jss09KPe+Pf6SoTx/sww89SiYiIiIiUkvNi9SpOf54oiUl1HTtmlL3/+c/FBUX4//nPz1KJiIiIiKi5kW2kTj0UKIlJVQfe2xK3ffpp4T79ydv6VKPkomIiIhIS6fmRbbj2rYl+txzVA0cmFK3WIzQiBEEZ8zwKJmIiIiItGRqXmTHCguJzZpF5aRJKWVLJCj85S8pmDoVEgmPwomIiIhIS6TmRRrm81Fx3XWU33Ybzpf6RyX/vvsIjRoFsZhH4URERESkpVHzIjsVHzuW2FNP4cLhlHrg+ecJDxiAbdjgUTIRERERaUnUvEhaqnv3JrJ4MYkDD0yp5736KkU9e+IrLfUomYiIiIi0FGpeJG2JHj2IlJRQc8QRKXVfWRnh4mL8f/mLR8lEREREpCVQ8yK7xHXsSGTpUqp+/OOUum/jRsKnn05gwQJvgomIiIhIs6fmRXZd69bEFiwgPmJEStnicUI//zn5t98OznkUTkRERESaKzUvsnsCAcrvvZeKqVO3Wyq4/noKJ02CqioPgomIiIhIc6XmRXafGZW//CWx6dNxgUDKUnDOHEJnngmbN3sUTkRERESaGzUvsseqhg4lunAhrnXrlHrgD3+gqE8fbN06j5KJiIiISHOi5kUaRc0PfkBk+XISnTql1P1vvUVRcTG+N97wKJmIiIiINBdqXqTRJA47jMiKFVR/5zspdd/69RT160deSYlHyURERESkOVDzIo3K7b8/0eefp6p//5S6RSKEhg0jOGuWR8lEREREJNepeZHGFwoRmz2byokTU8pWU0PhxRdT8KtfQSLhUTgRERERyVVqXiQz/H4qbrqJ8t/8BmeWspR/110UjhkDFRUehRMRERGRXKTmRTIqPmECsccfxxUWptSDzz5LeOBA7IsvPEomIiIiIrlGzYtkXHX//kQXLyax//4p9by//Y1wcTG+99/3KJmIiIiI5BI1L9Ikar79bSIlJdQcdlhK3b9mDeHiYvyvvOJRMhERERHJFU3WvJhZHzN7x8zeM7PLd7A+2sw2mNnrycfYZL2Hmb1sZqvN7A0zG7qD995tZpGm+Byy+1znzkSWLaP6Bz9Iqfu+/JLwwIEEFi70KJmIiIiI5IImaV7MzA/cB/QFjgCGm9kRO9h0nnOuR/LxcLIWA0Y6544E+gDTzGzvel/7u8A+mf0E0mj23pvoM88QH5rag1plJaGf/YzgXXeBcx6FExEREZFs1lRHXo4F3nPOrXHOxYG5wMB03uice9c5V5p8/jHwGbAf1DVFtwKTM5JaMiMYpPzBB6m47LLtlgp/9SsKLrkEqqs9CCYiIiIi2aypmpf2wNp6r9cla9salDw17Gkz67jtopkdCwSBrVd4XwAscs6tb+zAkmFmVE6ZQuz++3F5eSlL+TNnEho+HLZs8SiciIiIiGQjc01wio6ZDQb6OOe2XsdyDnCcc+6Cetu0ASLOuUozGw8Mdc79pN56O2AlMMo594qZHQTMB37snKs2s4hzrqj+9920aVPdhystLc3gJ5Q9sdff/84hl11GXiT1sqXYN75B6Z13UrXNlDIRERERaZ66detW97x169a27XpTNS/HA9c453onX08BcM7d1MD2fuBL51zr5OtW1DYuNzrnnk7W+gOPAFvvdNgJWOOcO3Tr16nfvHittLQ05TdDUvnefpvwkCH41q1LqSfatyc6bx6Jo47a4fu0Xxuf9mlmaL82Pu3TzNB+bXzap41P+zQzsm2/7qh5aarTxlYB3cysq5kFgWHAovobJI+sbDUAeDtZDwILgdlbGxcA59xi59yBzrkuzrkuQKx+4yK5JfHNbxJZsYKa7t1T6r6PPqKob1/yfv97j5KJiIiISLZokubFOVdN7fUpy6htSuY751ab2XVmNiC52aTkOOR/AZOA0cn6mcBJwOh6Y5R7NEVuaVruwAOJLF5MVe/eKXXbsoXQkCEEZs/2KJmIiIiIZIO8nW/SOJxzS4Al29Survd8CjBlB+97HHg8ja9ftLNtJAcUFRF78kkKLr+c/Bkz6spWU0No0iQqPvyQyqlTwbY7iigiIiIizVyT3aRSJG1+PxW33EL5DTfgtmlSCm67jcJx46Cy0qNwIiIiIuIVNS+SncyIn38+sccewxUUpCwFFywgfNpp2FdfeRRORERERLyg5kWyWvWAAUSff55E27Yp9byXXybcqxfBbaaTiYiIiEjzpeZFsl7N975HtKSEmkNTh8n5S0v55pgx+Fet8iiZiIiIiDQlNS+SExJduxItKaH6+ONT6oGvviJ86qnkLVrUwDtFREREpLlQ8yI5w+2zD9FnnyU+eHBK3SoqCI0aRfC++6AJbroqIiIiIt5Q8yK5JT+f8oceouLSS1PK5hyFU6dSMHky1NR4FE5EREREMknNi+Qen4/KK68kdvfdOL8/ZSl/xgxCI0ZANOpROBERERHJFDUvkrOqRo6kdNo03F57pdQDL75IuH9/7JNPPEomIiIiIpmg5kVy2ubvf5/I0qUk2rdPqee9/jpFPXvie/ttj5KJiIiISGNT8yI5L3HUUURKSqg5+uiUum/dOop698b/0kseJRMRERGRxqTmRZoFd9BBRJYsoaq4OKVumzcTHjSIwJNPepRMRERERBqLmhdpPvbai9hTT1H5s5+llK26mtB555F/000apSwiIiKSw9S8SPOSl0fFHXdQfu212y0V3HwzhRMmQDzuQTARERER2VNqXqT5MSP+f/9HbNYsXH5+ylJw3jzCgwbBxo0ehRMRERGR3aXmRZqtqtNPJ/rccyT23TelnvenP1HUuzdWVuZRMhERERHZHWpepFmr+f73iZaUUHPwwSl1/zvvUFRcjP+f//QomYiIiIjsKjUv0uwlDjmEaEkJ1ccdl1L3ffYZ4f79yVuyxKNkIiIiIrIr1LxIi+DatCH63HPETzstpW6xGKERIwhOn+5RMhERERFJl5oXaTkKCiifOZPK//u/lLI5R+Fll1EwZQrU1HgUTkRERER2Rs2LtCw+HxXXXkv5HXfgfKl//PMfeIDQyJEQi3kUTkRERES+jpoXaZHiY8YQmzsXFw6n1AOLFxM+9VTss888SiYiIiIiDVHzIi1Wda9eRJYsIdGuXUo977XXKCouxvfuux4lExEREZEdUfMiLVqie3ciJSXUHHFESt1XVlY7SvnPf/YomYiIiIhsS82LtHiuQwciL75I1cknp9Rt0ybCp59OYP58j5KJiIiISH1qXkQAWrUiNn8+8XPOSSlbVRWhcePIv/VWcM6jcCIiIiICal5E/icQoPzuu6m46qrtlgpuuIHCCy+EqioPgomIiIgIqHkRSWVG5SWXEJsxAxcMpiwFH3+c0JAhsGmTR+FEREREWjY1LyI7UDVkCNGFC0nsvXdKPbByJUV9+2Jr13qUTERERKTlUvMi0oCaE08kWlJConPnlLr/rbdqRym//rpHyURERERaprSaF6v1czP7vZm9kaydZGZnZjaeiLcS3boRWbGC6u9+N6Xu++QTivr3J2/ZMo+SiYiIiLQ86R55uQ44F3gI6JSsrQMuy0QokWzi9tuP6KJFVJ1ySkrdolFCw4cTfOQRj5KJiIiItCzpNi+jgVOcc3OBrfNi/wscnIlQIlknFCL22GNUnn9+StkSCQovuYSCq66CRMKjcCIiIiItQ7rNix+IJJ9vbV6K6tVEmj+/n4obbqD8lltwvtS/Ovn33EPoZz+D8nKPwomIiIg0f+k2L0uBO8wsH2qvgQGuB57PVDCRbBUfN47YE0/gQqGUeuC55wgPHIh9/rlHyURERESat3Sbl4uBA4FNQGtqj7h0Rte8SAtV3bcvkSVLSBxwQEo97+9/J1xcjO+99zxKJiIiItJ87bR5MTM/MBg4i9qL9b8PHOKcO905tyXD+USyVqJHDyIlJdQcfnhK3f/f/xIuLsb/yiseJRMRERFpnnbavDjnaoA7nHMVzrnPnHOrnHOfNEE2kaznOnUi8uKLVJ90Ukrd99VXhAcOJPDMMx4lExEREWl+0j1t7HkzOzWjSURy1d57E336aeLDh6eUrbKS0JgxBKdNA+caeLOIiIiIpCsvze0KgKfN7GVgLf+bOIZzbmQmgonklGCQ8vvvJ9GlCwU33ZSyVHjNNfjKyqi49VbIS/evnIiIiIhsK91/Sb2ZfIhIQ8yovOwyEp06UThpElZVVbeUP2sWvrVric2aBXvt5WFIERERkdyVVvPinLs200FEmouq4cNJHHQQ4XPOwTZvrqsHVqygqG9fovPn4w46yMOEIiIiIrkp3WteMLMfm9lMM1uW/PXkTAYTyWU1P/oRkeXLSXTsmFL3v/kmRT174ntTBzJFREREdlVazYuZjQXmA58AzwDrgafM7OcZzCaS0xKHH05kxQqqjzkmpe77+GOK+vYl73e/8yiZiIiISG5K98jLZKDYOXeFc266c24q0CtZF5EGuAMOIPrCC1T17ZtSty1bCJ15JoHZsz1KJiIiIpJ70m1e2gBvbVN7B9i3ceOINEPhMLHHH6dy3LiUstXUEJo0ifzrr4dEwqNwIiIiIrkj3eblz8AdZhYCMLMwcCvw10wFE2lW/H4qbrmF8htvxJmlLBXcfjuF48ZBZaVH4URERERyQ7rNywSgO7DJzD4FNiZfT8hUMJHmKH7eecRmz8YVFqbUg08/Tfi007Avv/QomYiIiEj2S6t5cc6td86dBHQFTgW6Oud+5Jz7KKPpRJqh6lNPJfr88yTatk2p5738MuFevfD9978eJRMRERHJbulOG+tlZt9wzq1zzv3dObfOzA4zs+JMBxRpjmq++10iK1ZQ061bSt3/3nuEe/bEv2qVR8lEREREsle6p43dB2zZprYlWReR3eC6dCG6fDnVJ56YUvd98QXhU08l77nnPEomIiIikp3SbV72d86t36a2HjiwkfOItChun32IPvMM8TPPTKlbRQWh0aMJ3nsvOOdROhEREZHskm7zssbMfrJN7ceATs4X2VP5+ZRPn07FpZemlM05Cq+8koLJk6G62qNwIiIiItkj3eblGuAZM7vdzM4zs9uB3wJXp/uNzKyPmb1jZu+Z2eU7WB9tZhvM7PXkY2yy3sPMXjaz1Wb2hpkNrfeeJ5Jf800zm2lmgXTziGQVMyqvvJLYPffg8vJSlvJnzCA0YgREIh6FExEREckO6U4bew7oBYSB/slfeyfrO2Vmfmqvj+kLHAEMN7MjdrDpPOdcj+Tj4WQtBox0zh0J9AGmmdneybUngMOBo4FCYGw6eUSyVdU55xBbsADXqlVKPbBsGUX9+2OffOJRMhERERHvpXvkheSUsQnOuf7JX3dlHNKxwHvOuTXOuTgwFxiY5vd91zlXmnz+MfAZsF/y9RKXBPwd6LALmUSyUvXJJxNZupREh9Q/zv5//Yuinj3xvf22R8lEREREvPW1zUvyVK8T6r0+xMz+YmabzOxFM2uX5vdpD6yt93pdsratQclTw542s447yHMsEATe36YeAM4BXkwzj0hWSxx5JJGSEmq+9a2Uum/dOop698b/0kseJRMRERHxjrmvmWRkZquASc65l5OvXwKi1J4CNgaocM6N2Ok3MRsM9HHObb2O5RzgOOfcBfW2aQNEnHOVZjYeGOqc+0m99XbASmCUc+6Vbb7+DCDqnLuofn3Tpk11H660tHRnMUWyji8W4+ArrmDvv/wlpZ7w+ymbOpUvTj3Vo2QiIiIija9bvXvgtW7d2rZd31nz8iW1Y5KrzWx/4GOgs3PuIzNrC7zhnDtoZyHM7HjgGudc7+TrKQDOuZsa2N4PfOmca5183YraxuVG59zT22z7K+AY4AznXKL+Wv3mxWulpaUpvxnSOFrEfq2upmDyZPJnztxuqWLyZCqnTAHb7u/2bmsR+9QD2q+NT/s0M7RfG5/2aePTPs2MbNuvO2pednbNS/1//B8P/Nc591Hy9RdAUZrfexXQzcy6mlkQGAYsqr/BNqegDQDeTtaDwEJg9g4al7FAb2D4to2LSLORl0fF7bdTfv312y0V3HILhRMmQDzuQTARERGRprWz5uVVYFLyyMdYYGm9tYOBz9P5Js65auACYBm1Tcl859xqM7vOzAYkN5uUHIf8L2ASMDpZPxM4CRhdb4xyj+Tag8ABwMvJetqjm0VyihnxCy8k+uijuPz8lKXgvHmEzzgDNm70KJyIiIhI08jbyfrFwPPArcB7wPh6a+cAf0z3GznnlgBLtqldXe/5FGDKDt73OPB4A19zZ/lFmpXq004j2q4dobPOwvfFF3X1vD//maLevYnOn4/r3NnDhCIiIiKZ87VHXpxzbznnDqH2upfDkqOKt5oGnJfRdCKynZrjjiNaUkLNIYek1P3vvENRz574//EPj5KJiIiIZFa6N6n8Yge1jc65WONHEpGdSRx8MNGSEqq///2Uum/DBsL9+5O3eLFHyUREREQyJ+2bVIpIdnH77kv02WeJn3FGSt3KywmdfTbBBx/0KJmIiIhIZqh5EcllBQWUP/wwFRdfnFI25yi8/HIKLr8camo8CiciIiLSuNS8iOQ6n4/KX/2K2LRpOL8/ZSn/wQcJjRwJMZ3hKSIiIrkv7ebFzA43s6vM7L56r7+VuWgisiuqRo8mNm8erij19kuBxYsJn3IK9tlnHiUTERERaRxpNS9mNoTascjtqR2RDLU3qLwjQ7lEZDdU9+xJZOlSEgcdlFLP+8c/KOrZE98773iUTERERGTPpXvk5Tqg2Dk3Adh6Av2/gO4ZSSUiuy1x9NFESkqoOfLIlLrvww8p6tUL/5/+5FEyERERkT2TbvOyP/BG8rmr96vb8eYi4iXXvj2RpUup+ulPU+q2aRPhM84gMG+eR8lEREREdl+6zctr/O90sa2GAX9v3Dgi0mhatSI2dy7xkSNTylZVRWj8ePJvuQWcfv4gIiIiuSMvze0mAcvN7FwgbGbLgG8AvTKWTET2XCBA+V13kejalYJrr01ZKrjxRnxlZZRPmwaBgEcBRURERNKX1pEX59x/gMOB+4ArgVnA0c650gxmE5HGYEblxRcTe+QRXDCYshR84glCQ4bApk0ehRMRERFJX7rTxtoD+c65+c65W51zc4GAmR20s/eKSHaoGjSI6LPPkthnn5R6YOVKivr0wdau9SiZiIiISHrSveblWaDDNrUOwMLGjSMimVRzwglEly+npkuXlLr/7bdrRym//ro3wURERETSkG7z8g3n3L/rF5KvD2/8SCKSSYlu3YiuWEH1976XUvd9+ilF/fvTWqOURUREWgzfm29SeMEF+N54Y+cbZ4F0m5cNZnZo/ULy9ReNH0lEMs21bUt00SKqBgxIqVs0yqGXXkrw4Yc9SiYiIiIZl0iQt3Qp4QED2OsHPyD4+OPkP/ig16nSkm7zMhP4rZmdYmZHmNmpwNOA/oUjkqsKC4k9+iiVF16YUrZEgsJLL6XgqqsgkfAonIiIiDS6LVsITp9O0Xe/S3j4cPL++Me6pcDTT5P3RfYfl0h3VPJvgCrgNqAjsJbaxuWODOUSkabg81Fx/fUkOnemYPJkrF6zkn/PPfjKyohNnw6FhR6GFBERkT1hH3xA/owZBOfMwTZv3vE28ThtliyB73+/idPtmrSaF+dcArg1+RCRZiY+diyJDh0IjRmDxWJ19cCiRYTXryf21FO4tm09TCgiIiK7xDn8L79M/gMPkLd4ccoPKLdVfcIJVE6cyKfdutGqCSPujnSPvGBmhwHdgaL6defczMYOJSJNr7pPHyJLlpA/aBDBeoeN81atItyzJ7GnnyZx6KFf8xVERETEc165CUkAACAASURBVPE4gWeeIf+BB/D/618NbuYCAaoGDaJywgQSPXrUFkuz/xaOaTUvZnYFcDXwLyBWb8lRez2MiDQDiR49+M+jj3Lk5Mn43367ru7/4APCxcXEnniCmhNO8DChiIiI7Iht2EBw1iyCjzyC79NPG9wu0bYt8TFjiJ97Lu6AA5owYeNI98jLRcCxzrncmKEmIrstfuCBRF58kfDIkeS99FJd3ffVV4RPO43yBx6gatAgDxOKiIjIVr433yT/wQcJLFiAVVY2uF3NkUdSOXEiVYMHQ0FBEyZsXOk2L+XAfzIZRESySOvWRBcsoPCiiwg++WRd2eJxQueeS8WHH1J50UVg5mFIERGRFiqRIG/ZstrrWepNDNuWM6O6Tx8qJ06k5oc/bBb/3063ebkKuMfMrgFSjkMlL+YXkeYmGKT8vvtIdOlCwY03piwVXHstvg8+oPy22yAQ8CigiIhIC7NlC8EnnyQ4fTr+NWsa3MwVFREfMYL4+PEkDj64CQNmXrrNy6PJX8fWqxm117z4GzOQiGQRMyonTybRqROFF16IVVXVLQUfewxbt47YrFnQKttnk4iIiOQuKysj/6GHvnbUMUCiUycqx48nfvbZ0Lp1EyZsOuk2L10zmkJEslrVsGEkDjqI8Nlnp/xHM/C731HUty/R+fNx7dt7mFBERKSZ2Y1Rx9X9+oG/eR9XSPc+L2UAZuYDDnDOrc9oKhHJOjUnnURk+XLCQ4bgW7u2ru5fvZqinj2JzptH4lvf8jChiIhIM7Ano45bAF86G5nZ3mb2JFABvJesDTCzX2cynIhkl8ThhxNZsYLqY45JqfvWr6eoXz/yVqzwKJmIiEhusw0byL/lFvY6+mhCEyY02Lgk2ralYvJktrz5JuUPPtiiGhdIs3kBHgQ2AZ2BeLL2MjA0E6FEJHu5Aw4g+sILVPXrl1K3SITQ0KEEHn3Uk1wiIiK5yPfmmxRecAF7HXUUBTfe2OA9WmqOPJLYvfey5c03qbziipy8R0tjSPeal58CBznnqszMATjnNpjZ/pmLJiJZKxwmNmcOBVdcQf706XVlq6khdNFFVJSVUXnVVeBL9+cjIiIiLUgLHnW8p9JtXjYBbYG6a13MrFP91yLSwvj9VNx8c+0o5SuuwJyrWyq48058ZWWU339/Tt8IS0REpFFp1PEeS7d5eRj4rZlNBXxmdjxwI7Wnk4lICxafOJFEx46Efv5zrLy8rh585hl8H39M7Mkncfvu62FCERERb2nUceNJt3m5GSgH7gMCwExgOnBXhnKJSA6pPuUUoi+8QGjYMHwbNtTV8155hXBxMbEFC/STIxERaVmcw//KK7Wnhr3wgkYdN5KdNi9m5qe2WRnnnFOzIiI7VPOd7xApKSF85pn43323ru5///3aBuapp6g59lgPE4qIiDQBjTrOqJ02L865GjPrBTTcLoqIAK5Ll9p7wYwYQd5f/lJX933xBeFTTyX20ENUDxzoYUIREZHMsA0bCM6aRfCRRxqcGAa1o47jY8YQP/fcFjsxbE+kOwroTuBaMwtmMoyINAN77030mWeIn3lmStkqKwmPGkXwnnug3sX9IiIiuUyjjptWute8XAgcCPzCzDYAdf/ycM51ykQwEclh+fmUT59OonNnCm69NWWp8Kqr8H3wARU33wx56f4nSEREJIto1LFn0v2Xw9kZTSEizY8ZlVOnkujcmcKLLsKqq+uW8h95BN/atcRmzoSiIg9DioiI7AKNOvZcWs2Lc+6lTAcRkeap6uyzSXToQHjkyJTxkIHlyynq14/ovHm4du08TCgiIvL1NOo4e6R1zYuZ5ZvZDWa2xsw2JWu9zOyCzMYTkeag5sc/JvLiiyQ6dEip+994g6LiYnyrV3uUTEREpAHO4X/5ZUIjR7LXMceQf999DTYu1SecQHTOHLb885/Ezz9fjUsG7coF+0cBI/jf9S6rgYmZCCUizU/iiCOIlJRQ0717St23bh1FffviX7nSm2AiIiL1xeME5s0jfPLJFPXtS2DRoh3eo8UFAsSHDWPLypVElyyh+tRTdY+WJpDuNS+nA4c656JmlgBwzn1kZu0zF01EmhvXrh2RxYsJnXsugWXL6uq2eTPhwYMpv/NOqs45x8OEIiLSUu3yqOMxY3AHHtiECQXSb17i225rZvsBXzR6IhFp3oqKiD3xBAWXXUb+I4/Ula26mtCFF1JRVkbl1KmayCIiIk3C9+ab5D/4IIEFC7DKyga3qznySConTqRq8GAoKGjChFJfus3LAuAxM7sYwMzaAdOAuZkKJiLNWF4eFbfdRqJLFwqvuiplqeC22/B9+CHl99wD+fkeBRQRkWZNo45zVrrNyxXAzcC/gRBQCswArstQLhFp7syIX3ghiU6dCI0fj1VU1C0F58/H99FHRJ94Avbe28OQIiLSrGjUcc5Ld1RyHLgYuDh5utjnzukW2SKy56oHDiTarh2h4cPxffG/M1Hz/vIXinr1Ijp/Pq5LF+8CiohIztOo4+Yj7dtbm1lr4DCgKPkaAOfc7zOSTERajJpjjyW6YgWhwYPxv/9+Xd3/7rsUFRcTmzuXmu98x8OEIiKSc5zD/8ortaeGvfDCDieGbVV9wglUTpxIdb9+mhiW5dJqXsxsNHAfEAFi9ZYcoGNpIrLHEl27Ei0pITRiBHkvv1xX923YQPiUU4g99FDtGEoREZGvE48TWLiQ4AMPkPf66w1u5gIBqgYNonLCBBI9ejRhQNkT6R55uQEY7JxbmskwItKyuX33JbpwIYXnn0/wt7+tq1t5OaGRI6m44Qbi553nYUIREclW9vnntaOOH35Yo46bsXSblzxgeSaDiIgAUFBA+YwZJDp3puCOO+rK5hyFV1yBr6yMihtv1GF9EREBNOq4pUm3ebkZuNLMrnfONXzCoIhIY/D5qLz6ahKdO1P4i19gNTV1S/nTp+P78ENiDz8M4bCHIUVExDOJBHlLl2rUcQvUYPNiZmupvaYFwIADgclmlnJjSudcp8zFE5GWrGrUKFyHDoRGjcIikbp6YOnS2utg5s7FHXCAhwlFRKRJJUcdH3XvvRSsXdvgZhp13Hx93ZGXs5sshYhIA6p/+lMiS5cSHjoU38cf19Xz/vlPinr2JLpgAYnDD/cwoYiIZJpGHctWDTYvzrmXGvMbmVkf4C7ADzzsnPvNNuujgVuBj5Kle51zD5tZD+ABoBVQA9zgnJuXfE9XYC7QBngNOCd5TxoRaUYSRx9NpKSE8Jln4l+9uq7uW7u29l4wjz9OzUkneZhQREQanUYdyw740tnIzAJmdq2ZrTGziuSv15pZMM33+6kdtdwXOAIYbmZH7GDTec65HsnHw8laDBjpnDsS6ANMM7Ott9y+GbjTOXco8BVwbjp5RCT3uPbtiSxdStVPf5pSt82bCQ8aROCppzxKJiIijSoeJzBvHuGTT6aob18CixbtsHFxgQDxYcPYsnIl0SVLasfpq3Fp9tJqXoBbgJ7ABKB78tefUNs8pONY4D3n3JrkkZG5wMB03uice9c5V5p8/jHwGbCf1d4l8yfA08lNHwNOSzOPiOSiVq2IzZ1LfNSolLJVVRGaOJH8m28G5xp4s4iIZDP7/HPyb72VvY4+mtD48Q3eoyXRti0fjx3Lln//m/IHH9Q9WlqYdKeNDQG6O+e2Xqz/jpn9A/gXcHEa728P1L+qah1w3A62G2RmJwHvAhc751KuxDKzY4Eg8D61p4ptdM5V1/ua7dP8PCKSqwIByqdNo6ZrVwqvuSZlqeCmm/CVlVE+bRoE0zowLCIiHvOtXl076nj+/K8fdXzEEbWjjocM4eO1a+mme7S0SObS+CmlmX0EfKte84KZtQXecM4dlMb7BwN9nHNjk6/PAY5zzl1Qb5s2QMQ5V2lm44Ghzrmf1FtvB6wERjnnXkl+/1eSp4xhZh2Bpc65o7a+Z9OmTXUfrrS0dKefU0Ryyz7Ll9P1mmvwVVWl1Dd/73u8f/PN1Oy1l0fJRETkayUStP7znzlg7lxarVrV4GbOjI0//CGfDRvGlu9+V6OOW4Bu3brVPW/duvV2v+HpHnlZADxvZtcCHwKdgSuB+Wm+/yOgY73XHfjfhfkA1G+MgIepPVUNADNrBSwGpjrnXkmWvwD2NrO85NGX7b5mffV3hBdKS0s9z9Acab82vpzap926Efv2twmddRa+r76qK7datYpvnX8+0XnzcJ2yY5p7Tu3XHKF9mhnar41P+7Se5Kjj4PTp+NesaXCz+qOOfQcfzIHU3rNjK+3TzMiF/ZruNS+TgRXUXnT/GnAP8AfgsjTfvwroZmZdkxf5DwMW1d8geWRlqwHA28l6EFgIzHbObb2+BVd7yOgPwOBkaRTwXJp5RKSZqDn+eKIlJdR07ZpS97/9NkXFxfgaOGdaRESajpWVUTB1Kq2OPJLCyy5rsHFJdOpE+Q03sHn1aipuvln3aJHtpHXkJXmR/dXJxy5zzlWb2QXAMmpHJc90zq02s+uAV51zi4BJZjYAqAa+BEYn334mcBLQJjlOGWC0c+51apunuWb2a+CfwCO7k09Eclvi0EOJlpQQOuss8v7+97q679NPKerXj9jMmVT36eNhQhGRFkijjiUDvrZ5MbMTgQHOue2OsJjZb4Bn653G9bWcc0uAJdvUrq73fAowZQfvexx4vIGvuYbaSWYi0sK5tm2JPvccoQkTCDz3v4OwFosROussKm65hfjYsR4mFBFpIeJxAgsXEnzggQYnhkHtqOOqQYOonDBBE8MkbTs7bewK4I8NrL0ETG3cOCIie6CwkNisWVROmpRStkSCwksvpeDKK+FrfvInIiK7b1dGHVdMnqxRx7JbdnbaWA/gxQbWStBpWiKSbXw+Kq67jkSnThRMnpxymkL+vffi+/BDYtOnQ2GhhyFFRJqP3Rl1TEFBEyaU5mRnzUsrau+rUr6DtQCgOaQikpXiY8eS6NiR0JgxWDRaVw8sWkR4/XpiTz6J228/DxOKiOSwRIK85ctrr2d56aUGN3NmVPfuTeXEidScdJJGHcse29lpY/8BejWw1iu5LiKSlap79yayeDGJbW5klrdqFeHiYny6/5OIyK7ZsoXgQw9R9N3vEh42rMHGxRUVUTl+PJHXXiM2dy41P/qRGhdpFDs78nInMN3M/NRenJ8wMx9wGrVjk3+R6YAiInsi0aMHkZISwkOH4n/rrbq6/4MPCBcXE3vySWpOOMHDhCIi2c/Kysh/6CGCc+Zgmzc3uF2iUycqx48nfvbZ0Lp1EyaUluJrmxfn3JNmdiDwGJBvZp8DbYFK4FfOuaeaIKOIyB5xHTsSWbqU0KhRBFaurKv7Nm4kfNpplN9/P1WDBzf8BUREWiKNOpYstNP7vDjn7jCzh4HjgTbU3tn+Zedcw223iEi2ad2a2IIFFF50EcEnnqgrWzxOaOxYKj78kMqLL9ZpDSIiGnUsWSzdm1RupvYGkyIiuSsQoPzee0l06ULBDTekLBVcdx2+Dz6g/PbbIRDwKKCIiHfs888JzppF8OGH8X36aYPbJdq2JT5mDPExY3DbXFMokmlpNS8iIs2GGZW//CWJTp0ovOACrKqqbik4eza2bh2xRx+FVq28yygi0oQ06lhyiZoXEWmRqoYOJdG+PeERI7BNm+rqgd//nqI+fYguWIBr397DhCIiGaRRx5KjdjYqWUSk2ar5wQ+ILF9OolOnlLr/rbco6tkT3xtveJRMRCRDIpH0Rh2Hw1SOG0fk1Vc16liyio68iEiLljjsMCIrVhAaPpy8116rq/vWr6eoXz9is2ZRXVzsYUIRkT1nZWXkz5hRe3rszkYdjxtXO+p4772bMKFIenTkRURaPLf//kSff56q/v1T6haJEBo2jMCjj3qSS0RkjziH/+WXCY0cyV7HHEP+vfc22LhUn3AC0Tlz2PLPfxK/4AI1LpK11LyIiACEQsRmz6Zy4sSUstXUELroIvKvuQa+5h4HIiJZIx4nMG8e4ZNPpqhvXwKLFu3wHi0uECA+bBhbVq4kumQJ1aeeqnu0SNbTaWMiIlv5/VTcdBOJzp0pmDIFc65uqWDaNHxlZZQ/8ICm7IhIVtKoY2kJ1LyIiGwjPmECiY4dCY0di5WX19WDCxfiW7+e2BNP4Nq08TChiMj/aNSxtCQ6bUxEZAeq+/cnungxif33T6nnvfIK4V698K1Z41EyERFqRx2/+CLhgQPZ68QTCc6Zs8PGxZlR1acPkeeeI/KXv1B1zjlqXCSnqXkREWlAzbe/TaSkhJrDDkup+99/n3DPnvj/9jePkolIi6VRx9LC6bQxEZGv4Tp3JrJsGeGzzybvz3+uq/u+/JLwgAHEpk+n+rTTPEwoIi1B2qOOO3akcvx4jTqWZktHXkREdmbvvYk+8wzxoUNTylZZSXj0aIJ33w31Lu4XEWkUuzLq+Pjjic6erVHH0uzpyIuISDqCQcoffJBEly4U3HxzylLh1Vfj++ADKm65BfL0n1UR2UPxOIGFCwk+8AB5r7/e4GYuEKDqjDOonDiRRI8eTRhQxDv6v6yISLrMqJwyhUTnzhROmoRVV9ct5c+ciW/dOmIzZ0JRkYchRSRXadSxyM6peRER2UVVZ51Fon17wueck3IKR2D5cor69SM6bx6uXTsPE4pILtGoY5H06ZoXEZHdUPOjHxFZtoxEhw4pdf8bb1DUsye+1as9SiYiOUGjjkV2i5oXEZHdlPjmN4msWEFN9+4pdd9HH1HUpw95f/iDR8lEJGtp1LHIHtFpYyIie8AdeCCRxYsJnXsugWXL6uq2ZQuhIUMov/PO2p+UikiLplHHIo1DzYuIyJ4qKiL25JMUXH45+TNm1JWtuprQhRdSUVYGZ57pYUAR8YRz+F95hYNvvZW9Vq7EEokGN60+/ngqJ06kul8/TS0U+Rr62yEi0hj8fipuuaV2lPKVV2L17vtScNttdP33v2H2bMjP9zCkiDQJjToWyRg1LyIijcWM+Pnnk+jYkdC4cVhFRd1Sm2XLqD79dGJPPIHbZx8PQ4pIpqQ96rhNm9pRx+eeq1HHIrtIzYuISCOrHjCAaLt2hIYPx/f553X1vL/+lXCvXkQXLMB16eJdQBFpVBp1LNJ0NG1MRCQDar73PaIlJdQcemhK3V9aSlHPnvhffdWjZCLSKHZh1PHGH/5Qo45FGomaFxGRDEl07Uq0pITq449Pqfs+/5zwKaeQ9/zzHiUTkd22G6OO37vjDo06Fmkkal5ERDLI7bMP0Wef5YvevVPqVlFBaORIgvfdB/Uu7heR7GRlZRRceSWtjjiCwsmT8a9Zs8PtEh07Uv7rX7N59eraIR6HHNLESUWaN13zIiKSafn5/Pe66wgffTQFt91WVzbnKJw6FV9ZGRU33QR+v4chRWQ7yVHH+Q88QN4LL2jUsUgW0N8uEZGm4PNReeWVJDp1ovDii7Gamrql/Icewvfhh8QeeQTCYQ9DigigUcciWUzNi4hIE6oaORLXoQOhUaOwLVvq6oEXXyTcvz+xefNwBxzgYUKRlkujjkWyn5oXEZEmVv2TnxBZupTw0KH4Pvqorp73+usU9exJdP58Et/8pocJRVoWjToWyR26YF9ExAOJo44iUlJCzdFHp9R9a9dS1Ls3/gYmGIlII9mFUcdVffpo1LFIllDzIiLiEXfQQUSWLKGquDilbps3Ex48mMBTT3mUTKQZ241Rx7G5czXqWCRL6LQxEREv7bUXsaeeouCXvyR/1qy6slVVEZo4kYqyMiovu0z/aBLZQ1ZWRv6MGQRnz8Y2b25wu0THjlSOH0/87LNh772bMKGIpEPNi4iI1/LyqLjjDhJdulD4q1+lLBX85jf4PviA8rvvhmDQo4AiOUqjjkWaHf3tFBHJBmbE/+//cJ06UThhQsq598G5c/F99BHROXP0k2CRdGjUsUizpeZFRCSLVJ1+Ool27QiddRa+L7+sq+f96U8U9elDdN48XOfOHiYUyV4adSzS/Kl5ERHJMjXf/z7RkhJCQ4bgX7Omru7/z38oKi4mNm8eNccc42FCkeyiUcciLYemjYmIZKHEIYcQLSmh+rjjUuq+zz4j3L8/eUuXepRMJEto1LFIi6TmRUQkS7k2bYg+9xzx005LqVssRmjECIIPPeRRMhEPadSxSIum08ZERLJZQQHlM2fiOncm/6676sqWSFA4eTK+Dz6g4vrrwe/3MKRI5mnUsYiAmhcRkezn81Fx7bUkOnem4NJLU8a95t9/P74PPyT20EMQCnkYUiQDNOpYRLahv90iIjkiPmYMiQ4dCP3sZ1g0WlcPvPAC4VNPJTZ3Lm6//TxMKNJINOpYRBqg5kVEJIdU9+pFZMkSwsOG4Vu/vq6e99prFPXsSXTBAhLf+IaHCUV2n0Ydi8jOqHkREckxie7diZSUED7zTPxvvVVX95WVEe7Vi9gTT1Bz4okeJhTZNRp1LCLp0rQxEZEc5Dp0IPLii1SdfHJK3bdxI+HTTyewYIFHyUTSpFHHIrIbdORFRCRXtWpFbP58Cn/xC4Jz5tSVLR4n9POfU1FWRuUll2g8rGSXSITgk08SnD4d//vvN7iZC4eJjxhBfPx4Eocc0oQBRSSbNdmRFzPrY2bvmNl7Znb5DtZHm9kGM3s9+Rhbb+1FM9toZi9s856fmtk/ktv/2cwObYrPIiKSNQIByu++m4qrrtpuqeDXv6bwwguhqsqDYCKprKyMgiuvpNURR1A4eXKDjUuiY0fKf/1rNq9eTcUtt6hxEZEUTXLkxcz8wH1AMbAOWGVmi5xzb22z6Tzn3AU7+BK3AiFg/Db1B4CBzrm3zew84EpgdKOGFxHJdmZUXnIJiU6dKDz/fCwer1sKPv449tFHxB59FFq39i6jtEwadSwijaypjrwcC7znnFvjnIsDc4GB6b7ZOfc7YMuOloBWyeetgY/3NKiISK6qGjKE6MKFJLa5MV/gD3+gqG9fbN06j5JJixOPE5g3j/DJJ1PUty+BRYt22Li4QID40KFsWbmS6NKlVA8YoMZFRL5WU/0Xoj2wtt7rdcBxO9hukJmdBLwLXOycW7uDbeobCywxs3JgM/D9xggrIpKrak48kWhJCeHBg/GVldXV/W+9VTtKed48Et27e5hQmjONOhaRTDPnXOa/idlgoI9zbmzy9TnAcfVPETOzNkDEOVdpZuOBoc65n9Rb/zFwqXPulHq1Z4CbnXN/M7NfAodt/R4AmzZtqvtwpaWlmfuAIiJZJu/LLzn0kksoevPNlHpNYSFrbrqJTRqlLI2o8L332H/uXNosXYqv3mmL24odeiifDh/Ol7174/LzmzChiOSKbt261T1v3br1dhNnmqp5OR64xjnXO/l6CoBz7qYGtvcDXzrnWter/Zh6zYuZ7Qe84pw7JPm6E/Cic+6Ire+p37x4rbS0NOU3QxqH9mvj0z7NDE/2ayxGaNw4Ai+kzDrB+XxU3HYb8TFjmjZPI9Of1cxIe78mEuQtX157PctLLzW4mTOjundvKidOpOakk1rk9Dv9WW182qeZkW37dUfNS1Nd87IK6GZmXc0sCAwDFtXfwMza1Xs5AHh7J1/zK6C1mW29lXRxGu8REWk5QiFijz1G5fnnp5QtkaDwF7+g4Oqr4WsuoBbZoUiE4EMPUfS97xEeNqzBxsWFw1SOG0fk1VeJzZ1LzY9+1CIbFxFpXE1yzYtzrtrMLgCWAX5gpnNutZldB7zqnFsETDKzAUA18CX1poaZ2Z+Aw4EiM1sHnOucW2ZmPwd+a2YJapuZ3P4xoohIY/P7qbjhBhKdO1Nw+eUpF03n33039uGHlD/wABQWehhScoGVlZE/YwbB2bOxzZsb3C7RsSOV48cTP/ts2GZ4hIjInmqykR7OuSXAkm1qV9d7PgWY0sB7f9hAfSGwsBFjiog0S/Fx40h07Ejo3HOxWKyuHnz2WXzr1xN78klcmzYeJpSspFHHIpJlmuwmlSIi4q3qvv/f3r2HR13deRx/fychd1TAlgYIQS1dha2LW63W+riPFVBUvFRFFBULVapWrYvXUpe2W9tatG7rXVEiUESg0loFS3C1tYrWtlIFLwUtkYvKRhBJQkKS+e4f80v8ZUgwmVxmJvN5Pc88zHx/lzm/w8nJfOec38k4qpYtIzpwYIt49ksvUThmDJG9/LVzyTBa6lhEUpR6GBGRDBIdNYqq8nIKJ0wg6803m+NZ77xD4Zgx1CxYQONRWnU+U1llJcUPPkjfpUu11LGIpCSNvIiIZBgfOpSqp56i4dhjW8Qj27ZReNpp9HnssSSVTJIlsnYt+VdcQd+RIxl8771tJi6NI0ZQc8cd7Fy7lroZM5S4iEiP08iLiEgm2m8/qpcsIf+qq8h55JHmsNXVUTBlCrvefZfdV12l1aF6My11LCJpSMmLiEimyslh1913Ex02jLyftPyzW/nf/z6RigpqZ83SPQy9TVUVOQsWkHPffWTt5T4nLyxk96RJ7J42jehBB/VgAUVE2qbfSCIimcyMuuuvJzp0KPlXXonV1zdvyp0zh8jGjdTMmQN9+yaxkNIV2rvUcV1xMdHLL9dSxyKSkpS8iIgI9eeeS3TQIAovuKDFB9s+K1dSNG4c1YsW4YMGJbGEkpAEljp+Y/hwhh9ySA8WUkSk/XTDvoiIAND4H/9B1YoVREtKWsSz1qyhaPRoImvWJKlk0mFa6lhEein1UCIi0ix68MFUrVxJwcSJZL/ySnM8smULRePGUVNWRsPxxyexhLI3VllJzpw55MyeraWORaRX0siLiIi04AMHUv3EE9SPG9cibjt3UjBhAn3mzk1SyaQt4aWO826+WUsdi0ivpZEXERHZU2EhNfPnk3fjjeTef39z2BobKbjySmorKqibMQMi+g4sabTUsYhkICUvIiLSuqwsan/2s9hSyjNmYO7Nm/Juu41IRQW77roLcnOTWMgMpKWORSSDKXkR6d8o7AAAETBJREFUEZG92n3ZZURLSii45BJs167meM6SJUQ2b6ZmwQK8X78kljAztHep42hJCXXTpmmpYxHplZS8iIjIp2oYP57q3/2OgokTiVRWNsezV62icOxYqhcvxocNS14Be6sEljpuOOkkrRgmIr2WJiuLiEi7NB5+OFUrV9I4fHiLeNa6dRSNHk3Wyy8nqWS9kJY6FhFplXo4ERFpNx82jOoVKyg4/3yyn3++OR6prKRw/Hhq7r8/9gFaEqKljkVE9k4jLyIi0iHerx/Vjz3G7gkTWsSttpaCyZPJuesuCN3cL59OSx2LiLSPRl5ERKTjcnPZdd99RIcOJe/WW5vD5k7+jBlENmyg9qc/haysJBYyxWmpYxGRDlPyIiIiiTGj7nvfI1paSv7VV2MNDc2bch94gMjGjdQ8+CAUFiaxkClISx2LiCRMyYuIiHRK/QUX4EOGUDB5coslfPs89RSFJ59MzcKFmt6EljoWEekKSl5ERKTTGo47jqrlyyk85xwimzY1x7NXr6Zo9GiqFy8mesghSSxhkmipYxGRLqUb9kVEpEtER46kqrycxkMPbRGPbNpE0QknkLWX+zp6HS11LCLSLZS8iIhIl/HiYqqWLaN+7NgWcfv4YwrPPJM+CxYkqWQ9wyoryZ01i76HHkrBtGlkr17d6n7RAQOovfZadr72Wmzhg1GjerikIiLpSV/viIhI1yoqombBAvKuu47chx5qDltDAwWXXUZtRQV1N9zQq1bNiqxdS+6999Jn0SKsrq7N/RpHjKDu0kupP+ssyM/vwRKKiPQOSl5ERKTrZWdTe9ttRA84gPybbmqxKe+WW4hs2MCuO+6AnJwkFbALaKljEZEep+RFRES6hxm7r7iCaEkJBdOmtRiRyHn0USJbtlA9b176railpY5FRJJGyYuIiHSrhtNPp7q4mILzziPy4YfN8eznnqPohBOoXrQILy1NYgnbR0sdi4gkn5IXERHpdo1HHkl1eTkFZ5/dYrQi6623KBozhppHH6XxsMOSWMI2aKljEZGUotXGRESkR0QPPJDq8nIajjqqRTyydSuFJ59M9rJlSSpZK7TUsYhISlLyIiIiPcb796f6N79h99e/3iJuNTUUTJpEzn33JalkQTkqK8m99VYtdSwikqL09ZCIiPSsvDx2zZ5NtLSUvNtvbw6bO/nXX09kwwZqf/QjyMrqsSJpqWMRkfSg5EVERHpeJELdzJlES0vJnz4da2xs3pR7zz1E3n2XmgcegIKC7iuDljoWEUk7Sl5ERCRp6i+6CB8yhIKLLsKqqprjfZ58ksLx46l55BH8s5/t2jfVUsciImlLyYuIiCRVw+jRVC1fTuE55xDZsqU5nv3Xv1I0ZgzVixcT/cIXOv0+WupYRCT96YZ9ERFJuugXv0hVeTmNI0e2iEcqKigaM4asP/0psRO7k7VqFQUXXkjfww4j984720xcGr7yFarnzmXnK6+w+9vfVuIiIpKClLyIiEhK8MGDqVq+nPrjj28Rtx07KDzjDPosWtT+k2mpYxGRXkk9tIiIpI599qFm4ULyp08nZ+7c5rDV11NwySXUVlRQd801bd40b5WV5JSVkTN7NpH332/zbaIDBrB7yhR2T52Kf+5zXX4ZIiLSPZS8iIhIaunTh12/+AXRAw4g7wc/aLEp7+abiVRUsCu0xDJA5PXXP1nquLa2zVNrqWMRkfSm5EVERFKPGXVXX0106FDyL70U2727eVPO/PnYpk1k3XQT2U89paWORUQyiJIXERFJWfVnnkm0uJiCSZOIbN/eHO/z7LP82wsvEAklNfG01LGISO+j5EVERFJa49FHU71iBQVnn03Whg3N8bYSFy11LCLSe2m1MRERSXnR4cOpXrmShiOOaHMfLXUsItL7KXkREZG04PvvT/Xjj1N/6qmfxLTUsYhIRlEPLyIi6SM/n5qHHyb76afZ+tprDJg4ES8uTnapRESkhyh5ERGR9GJGw+jRfFhaSn8lLiIiGUXTxkREREREJC0oeRERERERkbSg5EVERERERNKCkhcREREREUkLSl5ERERERCQtKHkREREREZG0oORFRERERETSgpIXERERERFJC0peREREREQkLSh5ERERERGRtGDunuwydJsdO3b03osTEREREenF9t13X4uPaeRFRERERETSgpIXERERERFJC7162piIiIiIiPQeGnkREREREZG0oOQlAWb2kJltNbM1oVh/Mys3s3XBv/3aOHZysM86M5scin/JzF4zs/Vm9ksz2+MGpd4u0Xo1s1FmtsrM1prZq2Z2TmhbmZn908xWB49RPXU9qaCTbbUxVG+Ph+IHmNlLQVt91MxyeuJaUkkn2upxoTpdbWa1ZnZ6sE1tdc86PTv4uY6a2eF7OfZEM3sraJM3hOIZ3VYTrVMzKzGzZ8zs9WDfq0Lbvm9mm0Pt9KSeuJZU0sm2uiH4Xb/azP4SirerX+6tOtFW/yWuT/3YzL4TbFNbbb1eZ5nZm8HnpaVmtl8bx6Zsv6rkJTFlwIlxsRuAp919OPB08LoFM+sPzASOBL4MzAx1UPcAFwPDg0f8+TNBGQnUK1ADXOjuI4Pj/yfuh/Fadx8VPFZ3Q7lTWRmJ1SnArlC9nRqK3wLc7u6fB7YDU7u4zOmgjATq1d2faapT4GvE2u6K0C5qqy2tAb4O/LGtg8wsC7gLGAeMAM41sxHB5kxvq2UkUKdAAzDd3UcARwGXh+oUYnXa1E6XdWWB00QZidVrk+OCugt/IG9vv9xblZFAnbr7W6E+9UvE+tSloV3UVves13LgX939UOAfwI3xB6V6v6rkJQHu/kdgW1z4NODh4PnDwOmtHHoCUO7u29x9O7EGdKKZFQP7uPuLHrsJaW4bx/dqidaru//D3dcFz7cAW4HPdGNR00Yn2mqrzMyIfeheksjxvUUX1etZwHJ3r+ni4qWl1urU3d9w97c+5dAvA+vd/R133w0sBE5TW028Tt39PXf/W/B8J/AGMLjbCppmOtFW9ybhfrk36KI6PR54290rurRwaayNel3h7g3ByxeBIa0cmtL9qpKXrjPQ3d8Lnr8PDGxln8HAxtDrTUFscPA8Pi7tq9dmZvZlIAd4OxS+ORgevd3McrupnOmkvXWaZ2Z/MbMXm6Y2AQOAj0Idn9rqJzrUVoGJwCNxMbXVjmurX1Vb7QJmNgw4DHgpFP520E4fyrTpTV3AgRVm9lczuyQU72j/IXtqrU9VW927KcDyVuIp3a8qeekGweiJlnHrYp9Wr8EI1jzgG+4eDcI3AgcDRwD9geu7u5zp5FPqtDSY1nAesal4B/VcydJbO9vqF4Hfh8Jqq5JSzKwI+DXwHXf/OAjfAxwEjALeA25LUvHS1THu/u/EpuNcbmbHxu+gzxAdF9x3cSqwOBRWW90LM5tBbIror5Jdlo5S8tJ1Pgg+kDR9MNnayj6bgZLQ6yFBbDMth+2a4tK+esXM9gGeBGa4+4tN8WD6g7t7HTCH2FBopmtXnbr75uDfd4BniX37+iGwn5llB7uprX6iXfUamAAsdff6poDaasLa6lfVVjvBzPoQS1x+5e6PNcXd/QN3bwy+IHoAtdMOCfWrW4ndm9FUfx3pP2RP44C/ufsHTQG11baZ2UXAKcAkb/1vpqR0v6rkpes8DjStHjYZ+G0r+/weGGtm/YLhy7HA74Oh4o/N7KhgPuGFbRyfiT61XoNvXJYCc919Sdy2pl8GRmxe5pr44zNQe+q0X9O0JTPbH/gq8HrQyT1D7H6NNo/PUO3pA5qcS9z0BrXVhL0MDA9WwMkhNnXkcbXVxAVt8EHgDXf/edy24tDLM1A7bTczKzSzvk3PiX0GaKq/jvQfsqc2+9SA2mrAzE4ErgNO3cs9l6ndr7q7Hh18EPsBeQ+oJzbfbyqxeYBPA+uAlUD/YN/DgdmhY6cA64PHN0Lxw4n9YL0N3EnwB0Qz6ZFovQLnB8esDj1GBdv+F3gtqNv5QFGyrzNN6vTooN7+Hvw7NXTOA4E/B214MZCb7OtMl3oNXg8j9k1VJO6caqt71ukZwfM64ANiX/YADAKWhY49idiqOW8TG31VW+1EnQLHEJu29GqoTz0p2DYvaKevEvvAXZzs60yjej0w6FP/DqyNa6ut9h+Z8ujkz38hsRGBfePOqbbaer2uJ3Y/S9PP9r1t1GvK9qsWFERERERERCSladqYiIiIiIikBSUvIiIiIiKSFpS8iIiIiIhIWlDyIiIiIiIiaUHJi4iIiIiIpAUlLyIi0m3MrMzMfpSk9zYzm2Nm283szz3wfkPNrMrMsrr7vUREMpWSFxGRDGJmG8xsa/BH8ppi3zSzZ5NYrO5yDDAGGOLuLf66tpl9N0g0qsys1swaQ6/XJvJm7v6uuxe5e2NXFF5ERPak5EVEJPNkAVcluxAdlcCIRimwwd2r4ze4+4+DRKMI+Bawqum1u4/sivKKiEjXU/IiIpJ5ZgHXmNl+8RvMbJiZuZllh2LPmtk3g+cXmdnzZna7mX1kZu+Y2dFBfGMwqjM57rT7m1m5me00sz+YWWno3AcH27aZ2VtmNiG0rczM7jGzZWZWDRzXSnkHmdnjwfHrzeziID4VmA18JRhN+UF7Kye4npfNbEfw79FxdfETM/uzmX1sZr81s/6t1Z2Z9Q+mrW0Jpq79Jojvb2ZPBPW3zcyeMzP9PhYRaQd1liIimecvwLPANQkefyTwKjAAWAAsBI4APg+cD9xpZkWh/ScB/w3sD6wGfgUQTF0rD87xWWAicLeZjQgdex5wM9AX+FMrZVkIbAIGAWcBPzazr7n7g7QcUZnZngsLEpEngV8G1/dz4EkzGxDa7UJgClAMNAT7tmYeUACMDK7v9iA+PSjzZ4CBwHcBb0/5REQynZIXEZHM9F/AFWb2mQSO/ae7zwnu7XgUKAF+6O517r4C2E0skWnypLv/0d3rgBnERkNKgFOITeua4+4N7v4K8Gvg7NCxv3X359096u614UIE5/gqcL2717r7amKjLRcmcE1NTgbWufu8oEyPAG8C40P7zHP3NcF0tJuACfFT2sysGBgHfMvdt7t7vbv/IdhcTyzxKQ3iz7m7khcRkXZQ8iIikoHcfQ3wBHBDAod/EHq+KzhffCw88rIx9L5VwDZiIyWlwJHB9KmPzOwjYqM0n2vt2FYMAra5+85QrAIY3IFrae2cFXGx+HNujNvWh9ioUlhJULbtrbzHLGA9sCKYdpfI/4GISEZS8iIikrlmAhfT8oN5083tBaFYOJlIREnTk2A6WX9gC7Ek4A/uvl/oUeTul4aO3duIxBagv5n1DcWGAps7UdYtxJKqsPhzlsRtqwcq447ZGJRtj/uK3H2nu0939wOBU4H/NLPjO1FmEZGMoeRFRCRDuft6YtO+rgzF/o/YB/XzzSzLzKYAB3XyrU4ys2PMLIfYvS8vuvtGYiM/XzCzC8ysT/A4wswOaWf5NwIvAD8xszwzOxSYCszvRFmXBWU6z8yyzewcYERQ1ibnm9kIMysAfggsiV8e2d3fA5YTu4enX3BtxwKY2Slm9nkzM2AH0AhEO1FmEZGMoeRFRCSz/RAojItdDFwLfEjsZvMXOvkeC4iN8mwDvkTspn6C6V5jid2ovwV4H7gFyO3Auc8FhgXHLwVmuvvKRAvq7h8SuxdnOrHrvw44xd3DIyvzgLKgvHmEkr84FxAblXkT2Ap8J4gPB1YCVcAq4G53fybRMouIZBLTPYIiIiLtE/wxz/nuPjvZZRERyUQaeRERERERkbSg5EVERERERNKCpo2JiIiIiEha0MiLiIiIiIikBSUvIiIiIiKSFpS8iIiIiIhIWlDyIiIiIiIiaUHJi4iIiIiIpAUlLyIiIiIikhb+H9IgRmiKYQVMAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["> #### **C) Determine the Optimal Number of Topics and then rerun model**"],"metadata":{"id":"oBCRgrWC3vQ7"}},{"cell_type":"code","source":["best_model_idx = coherence_df[coherence_df['Number of Topics'] == 10].index[0]\n","best_lda_model = lda_models[best_model_idx]\n","best_lda_model.num_topics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5zIR5do63ufQ","executionInfo":{"status":"ok","timestamp":1662840521558,"user_tz":360,"elapsed":154,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"aa7e4cc8-4034-452f-80bb-650264e68f7a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["topics = [[(term, round(wt, 3)) \n","               for term, wt in best_lda_model.show_topic(n, topn=20)] \n","                   for n in range(0, best_lda_model.num_topics)]\n","'''\n","for idx, topic in enumerate(topics):\n","    print('Topic #'+str(idx+1)+':')\n","    print([term for term, wt in topic])\n","    print()\n","'''"],"metadata":{"id":"VL8WdNSz3-65"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["> #### **D) Display as Term-Topic Dataframe**"],"metadata":{"id":"Zbr6bt9P4RiL"}},{"cell_type":"code","source":["pd.set_option('display.max_colwidth', -1)\n","topics_df = pd.DataFrame([', '.join([term for term, wt in topic])  \n","                              for topic in topics],\n","                         columns = ['Terms per Topic'],\n","                         index=['Topic'+str(t) for t in range(1, best_lda_model.num_topics+1)]\n","                         )\n","topics_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":418},"id":"o3dfgJRm4V_7","executionInfo":{"status":"ok","timestamp":1662840566037,"user_tz":360,"elapsed":145,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"81b854de-ff25-4068-9521-4cfca2b3e6cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n","  \"\"\"Entry point for launching an IPython kernel.\n"]},{"output_type":"execute_result","data":{"text/plain":["                                                                                                                                                                                                      Terms per Topic\n","Topic1   training, classification, word, class, trained, classifier, feature, recognition, test, task, training_set, pattern, experiment, table, speech, character, accuracy, test_set, vector, technique            \n","Topic2   equation, vector, matrix, solution, dynamic, linear, rate, noise, training, gradient, convergence, nonlinear, eq, optimal, average, minimum, optimization, curve, line, constraint                          \n","Topic3   class, bound, size, theorem, probability, linear, theory, complexity, defined, approximation, define, threshold, loss, xi, proof, hypothesis, section, assume, polynomial, concept                          \n","Topic4   signal, noise, filter, source, frequency, response, subject, component, target, channel, human, temporal, rate, detection, correlation, study, task, stimulus, sound, effect                                \n","Topic5   image, feature, object, motion, map, visual, local, direction, pixel, position, region, location, representation, distance, field, view, face, surface, edge, vector                                        \n","Topic6   neuron, circuit, current, chip, analog, voltage, bit, implementation, neural, design, parallel, computation, processor, operation, element, gain, synapse, application, array, device                       \n","Topic7   unit, pattern, rule, layer, node, hidden_unit, state, activation, net, sequence, memory, representation, structure, architecture, recurrent, connection, module, vector, level, connectionist               \n","Topic8   distribution, estimate, variable, probability, gaussian, prior, sample, mixture, density, prediction, estimation, approximation, variance, bayesian, component, likelihood, regression, procedure, log, step\n","Topic9   state, control, action, step, task, trajectory, policy, environment, controller, optimal, reinforcement_learning, path, goal, search, robot, position, dynamic, move, current, change                       \n","Topic10  neuron, cell, response, activity, stimulus, pattern, spike, synaptic, neural, cortical, et_al, connection, firing, effect, cortex, visual, mechanism, simulation, layer, receptive_field                    "],"text/html":["\n","  <div id=\"df-061ab566-5eee-472c-ae54-f1564332f607\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Terms per Topic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Topic1</th>\n","      <td>training, classification, word, class, trained, classifier, feature, recognition, test, task, training_set, pattern, experiment, table, speech, character, accuracy, test_set, vector, technique</td>\n","    </tr>\n","    <tr>\n","      <th>Topic2</th>\n","      <td>equation, vector, matrix, solution, dynamic, linear, rate, noise, training, gradient, convergence, nonlinear, eq, optimal, average, minimum, optimization, curve, line, constraint</td>\n","    </tr>\n","    <tr>\n","      <th>Topic3</th>\n","      <td>class, bound, size, theorem, probability, linear, theory, complexity, defined, approximation, define, threshold, loss, xi, proof, hypothesis, section, assume, polynomial, concept</td>\n","    </tr>\n","    <tr>\n","      <th>Topic4</th>\n","      <td>signal, noise, filter, source, frequency, response, subject, component, target, channel, human, temporal, rate, detection, correlation, study, task, stimulus, sound, effect</td>\n","    </tr>\n","    <tr>\n","      <th>Topic5</th>\n","      <td>image, feature, object, motion, map, visual, local, direction, pixel, position, region, location, representation, distance, field, view, face, surface, edge, vector</td>\n","    </tr>\n","    <tr>\n","      <th>Topic6</th>\n","      <td>neuron, circuit, current, chip, analog, voltage, bit, implementation, neural, design, parallel, computation, processor, operation, element, gain, synapse, application, array, device</td>\n","    </tr>\n","    <tr>\n","      <th>Topic7</th>\n","      <td>unit, pattern, rule, layer, node, hidden_unit, state, activation, net, sequence, memory, representation, structure, architecture, recurrent, connection, module, vector, level, connectionist</td>\n","    </tr>\n","    <tr>\n","      <th>Topic8</th>\n","      <td>distribution, estimate, variable, probability, gaussian, prior, sample, mixture, density, prediction, estimation, approximation, variance, bayesian, component, likelihood, regression, procedure, log, step</td>\n","    </tr>\n","    <tr>\n","      <th>Topic9</th>\n","      <td>state, control, action, step, task, trajectory, policy, environment, controller, optimal, reinforcement_learning, path, goal, search, robot, position, dynamic, move, current, change</td>\n","    </tr>\n","    <tr>\n","      <th>Topic10</th>\n","      <td>neuron, cell, response, activity, stimulus, pattern, spike, synaptic, neural, cortical, et_al, connection, firing, effect, cortex, visual, mechanism, simulation, layer, receptive_field</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-061ab566-5eee-472c-ae54-f1564332f607')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-061ab566-5eee-472c-ae54-f1564332f607 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-061ab566-5eee-472c-ae54-f1564332f607');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":67}]},{"cell_type":"markdown","source":["> #### **E) Topic Model Interpretation**\n","\n","One meaningful way we can interpret our topic models is to see what the most dominant (highest weighted) topics were in specific research papers. Let's create a dataframe containing the documet number, its most dominant topic number, the % contribution of that topic, the topic description and a exerpt from the beginning of the paper."],"metadata":{"id":"qIquI71R5NTj"}},{"cell_type":"code","source":["tm_results = best_lda_model[bow_corpus]                                                           # ~ 21 seconds to run\n","\n","corpus_topics = [sorted(topics, key=lambda record: -record[1])[0] \n","                     for topics in tm_results]\n","\n","corpus_topic_df = pd.DataFrame()\n","corpus_topic_df['Document'] = range(0, len(papers))\n","corpus_topic_df['Dominant Topic'] = [item[0]+1 for item in corpus_topics]\n","corpus_topic_df['Contribution %'] = [round(item[1]*100, 2) for item in corpus_topics]\n","corpus_topic_df['Topic Desc'] = [topics_df.iloc[t[0]]['Terms per Topic'] for t in corpus_topics]\n","corpus_topic_df['Paper'] = papers"],"metadata":{"id":"Q1xvsUaP50es"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.set_option('display.max_colwidth', 200)\n","(corpus_topic_df[corpus_topic_df['Document']\n","                 .isin([682, 10, 392, 1622, 17, \n","                        906, 1005, 503, 13, 736])])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":772},"id":"IeswCd_-6Aam","executionInfo":{"status":"ok","timestamp":1662840727450,"user_tz":360,"elapsed":157,"user":{"displayName":"Carly Fox","userId":"09164108851212115743"}},"outputId":"aca8f21d-4fb4-483c-cadf-8f83b5644f5b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Document  Dominant Topic  Contribution %  \\\n","10          10               7           29.74   \n","13          13               6           68.42   \n","17          17               3           40.41   \n","392        392               9           21.74   \n","503        503               5           38.31   \n","682        682              10           51.68   \n","736        736               2           37.09   \n","906        906               5           55.13   \n","1005      1005               8           49.47   \n","1622      1622               3           34.43   \n","\n","                                                                                                                                                                                                   Topic Desc  \\\n","10              unit, pattern, rule, layer, node, hidden_unit, state, activation, net, sequence, memory, representation, structure, architecture, recurrent, connection, module, vector, level, connectionist   \n","13                      neuron, circuit, current, chip, analog, voltage, bit, implementation, neural, design, parallel, computation, processor, operation, element, gain, synapse, application, array, device   \n","17                         class, bound, size, theorem, probability, linear, theory, complexity, defined, approximation, define, threshold, loss, xi, proof, hypothesis, section, assume, polynomial, concept   \n","392                     state, control, action, step, task, trajectory, policy, environment, controller, optimal, reinforcement_learning, path, goal, search, robot, position, dynamic, move, current, change   \n","503                                      image, feature, object, motion, map, visual, local, direction, pixel, position, region, location, representation, distance, field, view, face, surface, edge, vector   \n","682                  neuron, cell, response, activity, stimulus, pattern, spike, synaptic, neural, cortical, et_al, connection, firing, effect, cortex, visual, mechanism, simulation, layer, receptive_field   \n","736                        equation, vector, matrix, solution, dynamic, linear, rate, noise, training, gradient, convergence, nonlinear, eq, optimal, average, minimum, optimization, curve, line, constraint   \n","906                                      image, feature, object, motion, map, visual, local, direction, pixel, position, region, location, representation, distance, field, view, face, surface, edge, vector   \n","1005  distribution, estimate, variable, probability, gaussian, prior, sample, mixture, density, prediction, estimation, approximation, variance, bayesian, component, likelihood, regression, procedure, l...   \n","1622                       class, bound, size, theorem, probability, linear, theory, complexity, defined, approximation, define, threshold, loss, xi, proof, hypothesis, section, assume, polynomial, concept   \n","\n","                                                                                                                                                                                                        Paper  \n","10    233 \\nHIGH ORDER NEURAL NETWORKS FOR EFFICIENT \\nASSOCIATIVE MEMORY DESIGN \\nI. GUYON*, L. PERSONNAZ*, J.P. NADAL** and G. DREYFUS* \\n* Ecole SupOrieure de Physique et de Chimie Industrielles de l...  \n","13    515 \\nMICROELECTRONIC IMPLEMENTATIONS OF CONNECTIONIST \\nNEURAL NETWORKS \\nStuart Mackie, Hans P. Graf, Daniel B. Schwartz, and John S. Denker \\nAT&T Bell Labs, Holmdel, NJ 07733 \\nAbstract \\nIn t...  \n","17    1 \\nCONNECTIVITY VERSUS ENTROPY \\nYaser S. Abu-Mostafa \\nCalifornia Institute of Technology \\nPasadena, CA 91125 \\nABSTRACT \\nHow does the connectivity of a neural network (number of synapses per ...  \n","392   Modeling Time Varying Systems \\nUsing Hidden Control Neural Architecture \\nEsther Levin \\nAT&T Bell Laboratories \\nSpeech Research Department \\nMurray Hill, NJ 07974 USA \\nABSTRACT \\nMulti-layered...  \n","503   Learning to Segment Images \\nUsing Dynamic Feature Binding \\nMichael C. Moser \\nDept. of Comp. Science & \\nInst. of Cognitive Science \\nUniversity of Colorado \\nBoulder, CO 80309-0430 \\nRichard S....  \n","682   Unsmearing Visual Motion: \\nDevelopment of Long-Range \\nHorizontal Intrinsic Connections \\nKevin E. Martin Jonathan A. Marshall \\nDepartment of Computer Science, CB 3175, Sitterson Hall \\nUniversi...  \n","736   Optimality Criteria for LMS and \\nBackpropagation \\nBabak Hassibi \\nInformation Systems Laboratory \\nStanford University \\nStanford, CA 94305 \\nAll H. Sayed \\nDept. of Elec. and Comp. Engr. \\nUniv...  \n","906   Nonlinear Image Interpolation using \\nManifold Learning \\nChristoph Bregler \\nComputer Science Division \\nUniversity of California \\nBerkeley, CA 94720 \\nbregler@cs.berkeley.edu \\nStephen M. Omohu...  \n","1005  Exploiting Tractable Substructures \\nin Intractable Networks \\nLawrence K. Saul and Michael I. Jordan \\n{lksaul, j ordar}*psyche. mir. edu \\nCenter for Biological and Computational Learning \\nMas...  \n","1622  Model selection in clustering by uniform \\nconvergence bounds* \\nJoachim M. Buhmann nd Marcus Held \\nInstitut fiir Informatik III, \\nRSmerstrafie 164, D-53117 Bonn, Germany \\n{jb,held)@cs.uni-bon...  "],"text/html":["\n","  <div id=\"df-62048d7e-1086-4104-8733-47a260b65678\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Document</th>\n","      <th>Dominant Topic</th>\n","      <th>Contribution %</th>\n","      <th>Topic Desc</th>\n","      <th>Paper</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>7</td>\n","      <td>29.74</td>\n","      <td>unit, pattern, rule, layer, node, hidden_unit, state, activation, net, sequence, memory, representation, structure, architecture, recurrent, connection, module, vector, level, connectionist</td>\n","      <td>233 \\nHIGH ORDER NEURAL NETWORKS FOR EFFICIENT \\nASSOCIATIVE MEMORY DESIGN \\nI. GUYON*, L. PERSONNAZ*, J.P. NADAL** and G. DREYFUS* \\n* Ecole SupOrieure de Physique et de Chimie Industrielles de l...</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>6</td>\n","      <td>68.42</td>\n","      <td>neuron, circuit, current, chip, analog, voltage, bit, implementation, neural, design, parallel, computation, processor, operation, element, gain, synapse, application, array, device</td>\n","      <td>515 \\nMICROELECTRONIC IMPLEMENTATIONS OF CONNECTIONIST \\nNEURAL NETWORKS \\nStuart Mackie, Hans P. Graf, Daniel B. Schwartz, and John S. Denker \\nAT&amp;T Bell Labs, Holmdel, NJ 07733 \\nAbstract \\nIn t...</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>17</td>\n","      <td>3</td>\n","      <td>40.41</td>\n","      <td>class, bound, size, theorem, probability, linear, theory, complexity, defined, approximation, define, threshold, loss, xi, proof, hypothesis, section, assume, polynomial, concept</td>\n","      <td>1 \\nCONNECTIVITY VERSUS ENTROPY \\nYaser S. Abu-Mostafa \\nCalifornia Institute of Technology \\nPasadena, CA 91125 \\nABSTRACT \\nHow does the connectivity of a neural network (number of synapses per ...</td>\n","    </tr>\n","    <tr>\n","      <th>392</th>\n","      <td>392</td>\n","      <td>9</td>\n","      <td>21.74</td>\n","      <td>state, control, action, step, task, trajectory, policy, environment, controller, optimal, reinforcement_learning, path, goal, search, robot, position, dynamic, move, current, change</td>\n","      <td>Modeling Time Varying Systems \\nUsing Hidden Control Neural Architecture \\nEsther Levin \\nAT&amp;T Bell Laboratories \\nSpeech Research Department \\nMurray Hill, NJ 07974 USA \\nABSTRACT \\nMulti-layered...</td>\n","    </tr>\n","    <tr>\n","      <th>503</th>\n","      <td>503</td>\n","      <td>5</td>\n","      <td>38.31</td>\n","      <td>image, feature, object, motion, map, visual, local, direction, pixel, position, region, location, representation, distance, field, view, face, surface, edge, vector</td>\n","      <td>Learning to Segment Images \\nUsing Dynamic Feature Binding \\nMichael C. Moser \\nDept. of Comp. Science &amp; \\nInst. of Cognitive Science \\nUniversity of Colorado \\nBoulder, CO 80309-0430 \\nRichard S....</td>\n","    </tr>\n","    <tr>\n","      <th>682</th>\n","      <td>682</td>\n","      <td>10</td>\n","      <td>51.68</td>\n","      <td>neuron, cell, response, activity, stimulus, pattern, spike, synaptic, neural, cortical, et_al, connection, firing, effect, cortex, visual, mechanism, simulation, layer, receptive_field</td>\n","      <td>Unsmearing Visual Motion: \\nDevelopment of Long-Range \\nHorizontal Intrinsic Connections \\nKevin E. Martin Jonathan A. Marshall \\nDepartment of Computer Science, CB 3175, Sitterson Hall \\nUniversi...</td>\n","    </tr>\n","    <tr>\n","      <th>736</th>\n","      <td>736</td>\n","      <td>2</td>\n","      <td>37.09</td>\n","      <td>equation, vector, matrix, solution, dynamic, linear, rate, noise, training, gradient, convergence, nonlinear, eq, optimal, average, minimum, optimization, curve, line, constraint</td>\n","      <td>Optimality Criteria for LMS and \\nBackpropagation \\nBabak Hassibi \\nInformation Systems Laboratory \\nStanford University \\nStanford, CA 94305 \\nAll H. Sayed \\nDept. of Elec. and Comp. Engr. \\nUniv...</td>\n","    </tr>\n","    <tr>\n","      <th>906</th>\n","      <td>906</td>\n","      <td>5</td>\n","      <td>55.13</td>\n","      <td>image, feature, object, motion, map, visual, local, direction, pixel, position, region, location, representation, distance, field, view, face, surface, edge, vector</td>\n","      <td>Nonlinear Image Interpolation using \\nManifold Learning \\nChristoph Bregler \\nComputer Science Division \\nUniversity of California \\nBerkeley, CA 94720 \\nbregler@cs.berkeley.edu \\nStephen M. Omohu...</td>\n","    </tr>\n","    <tr>\n","      <th>1005</th>\n","      <td>1005</td>\n","      <td>8</td>\n","      <td>49.47</td>\n","      <td>distribution, estimate, variable, probability, gaussian, prior, sample, mixture, density, prediction, estimation, approximation, variance, bayesian, component, likelihood, regression, procedure, l...</td>\n","      <td>Exploiting Tractable Substructures \\nin Intractable Networks \\nLawrence K. Saul and Michael I. Jordan \\n{lksaul, j ordar}*psyche. mir. edu \\nCenter for Biological and Computational Learning \\nMas...</td>\n","    </tr>\n","    <tr>\n","      <th>1622</th>\n","      <td>1622</td>\n","      <td>3</td>\n","      <td>34.43</td>\n","      <td>class, bound, size, theorem, probability, linear, theory, complexity, defined, approximation, define, threshold, loss, xi, proof, hypothesis, section, assume, polynomial, concept</td>\n","      <td>Model selection in clustering by uniform \\nconvergence bounds* \\nJoachim M. Buhmann nd Marcus Held \\nInstitut fiir Informatik III, \\nRSmerstrafie 164, D-53117 Bonn, Germany \\n{jb,held)@cs.uni-bon...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62048d7e-1086-4104-8733-47a260b65678')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-62048d7e-1086-4104-8733-47a260b65678 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-62048d7e-1086-4104-8733-47a260b65678');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":82}]},{"cell_type":"markdown","source":["**Examine several of the papers displayed in our dataframe. How would you characterize the dominant topics for these papers? Do they appear to reasonably match up with the paper title?**"],"metadata":{"id":"xvX0DRM56z4v"}},{"cell_type":"markdown","source":[],"metadata":{"id":"WwaKMusQ7Sq_"}},{"cell_type":"markdown","source":["**We've learned about using topic modeling in the context of trying to briefly summarize the overall themes/topics within a large corpus of research articles. What is another context where topic modeling could be useful?**"],"metadata":{"id":"B-iP66em7S5W"}},{"cell_type":"markdown","source":[],"metadata":{"id":"guE5Sz857eCZ"}}]}